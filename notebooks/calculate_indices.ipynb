{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# License: MIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import itertools\n",
    "import os\n",
    "import time\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "import reanalysis_dbns.indices as rdi\n",
    "import reanalysis_dbns.utils as rdu\n",
    "\n",
    "from cartopy.util import add_cyclic_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teleconnection indices calculations\n",
    "\n",
    "This notebook generates the teleconnection indices that\n",
    "are used as the data for fitting DBNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_DIR = os.path.join(os.getenv('HOME'), 'projects', 'reanalysis-dbns')\n",
    "\n",
    "DATA_DIR = os.path.join(PROJECT_DIR, 'data')\n",
    "RESULTS_DIR = os.path.join(PROJECT_DIR, 'results')\n",
    "\n",
    "REF_INDICES_RESULTS_DIR = os.path.join(RESULTS_DIR, 'reference-indices')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PERIOD = [np.datetime64('1979-01-01'), np.datetime64('2001-12-30')]\n",
    "START_YEAR = 1940 # earliest year allowed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REANALYSES = ['jra55', 'nnr1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reanalysis_full_name(reanalysis):\n",
    "    \"\"\"Get full name for reanalysis.\"\"\"\n",
    "    \n",
    "    if reanalysis == 'hadisst':\n",
    "        return 'HadISST'\n",
    "\n",
    "    if reanalysis == 'nnr1':\n",
    "        return 'NNR1'\n",
    "    \n",
    "    if reanalysis == 'jra55':\n",
    "        return 'JRA-55'\n",
    "    \n",
    "    raise ValueError(\"Unrecognized reanalysis '%r'\" % reanalysis)\n",
    "\n",
    "    \n",
    "def get_reanalysis_results_dir(reanalysis, results_dir=RESULTS_DIR):\n",
    "    \"\"\"Get path to results for given reanalysis.\"\"\"\n",
    "    return os.path.join(results_dir, reanalysis)\n",
    "\n",
    "\n",
    "def get_reanalysis_fields_dir(reanalysis, results_dir=RESULTS_DIR):\n",
    "    \"\"\"Get path to directory containing reanalysis fields.\"\"\"\n",
    "    reanalysis_dir = get_reanalysis_results_dir(reanalysis, results_dir=results_dir)\n",
    "    return os.path.join(reanalysis_dir, 'fields')\n",
    "\n",
    "\n",
    "def get_reanalysis_eofs_dir(reanalysis, results_dir=RESULTS_DIR):\n",
    "    \"\"\"Get path to directory containing reanalysis EOFs.\"\"\"\n",
    "    reanalysis_dir = get_reanalysis_results_dir(reanalysis, results_dir=results_dir)\n",
    "    return os.path.join(reanalysis_dir, 'eofs')\n",
    "\n",
    "\n",
    "def get_reanalysis_eofs_nc_dir(reanalysis, results_dir=RESULTS_DIR):\n",
    "    \"\"\"Get path to directory containing reanalysis EOFs in netCDF format.\"\"\"\n",
    "    reanalysis_dir = get_reanalysis_eofs_dir(reanalysis, results_dir=results_dir)\n",
    "    return os.path.join(reanalysis_dir, 'nc')\n",
    "\n",
    "\n",
    "def get_reanalysis_eofs_plt_dir(reanalysis, results_dir=RESULTS_DIR):\n",
    "    \"\"\"Get path to directory containing plots of reanalysis EOFs.\"\"\"\n",
    "    reanalysis_dir = get_reanalysis_eofs_dir(reanalysis, results_dir=results_dir)\n",
    "    return os.path.join(reanalysis_dir, 'plt')\n",
    "\n",
    "\n",
    "def get_reanalysis_indices_dir(reanalysis, results_dir=RESULTS_DIR):\n",
    "    \"\"\"Get path to directory containing reanalysis indices.\"\"\"\n",
    "    reanalysis_dir = get_reanalysis_results_dir(reanalysis, results_dir=results_dir)\n",
    "    return os.path.join(reanalysis_dir, 'indices')\n",
    "\n",
    "\n",
    "def get_reanalysis_indices_csv_dir(reanalysis, results_dir=RESULTS_DIR):\n",
    "    \"\"\"Get path to directory containing reanalysis indices in CSV format.\"\"\"\n",
    "    indices_dir = get_reanalysis_indices_dir(reanalysis, results_dir=results_dir)\n",
    "    return os.path.join(indices_dir, 'csv')\n",
    "\n",
    "\n",
    "def get_reanalysis_indices_nc_dir(reanalysis, results_dir=RESULTS_DIR):\n",
    "    \"\"\"Get path to directory containing reanalysis indices in netCDF format.\"\"\"\n",
    "    indices_dir = get_reanalysis_indices_dir(reanalysis, results_dir=results_dir)\n",
    "    return os.path.join(indices_dir, 'nc')\n",
    "\n",
    "\n",
    "def get_reanalysis_indices_plt_dir(reanalysis, results_dir=RESULTS_DIR):\n",
    "    \"\"\"Get path to directory containing plots of reanalysis indices.\"\"\"\n",
    "    indices_dir = get_reanalysis_indices_dir(reanalysis, results_dir=results_dir)\n",
    "    return os.path.join(indices_dir, 'plt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_timespan_string(time_span):\n",
    "    \"\"\"Get string for time period used in file names.\"\"\"\n",
    "    return '{}_{}'.format(\n",
    "        pd.to_datetime(time_span[0]).strftime('%Y%m%d'),\n",
    "        pd.to_datetime(time_span[1]).strftime('%Y%m%d'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_index_datafile_name(reanalysis, index, base_period=BASE_PERIOD,\n",
    "                            frequency='daily', ext='csv'):\n",
    "    \"\"\"Get filename for datafile containing index data.\"\"\"\n",
    "    \n",
    "    base_period_str = '{}_{}'.format(\n",
    "        pd.to_datetime(base_period[0]).strftime('%Y%m%d'),\n",
    "        pd.to_datetime(base_period[1]).strftime('%Y%m%d'))\n",
    "    \n",
    "    return '.'.join([reanalysis, base_period_str, index, frequency, ext])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_reference_index_csv(filename, time_name='time'):\n",
    "    \"\"\"Read index CSV file provided in format for downloaded indices.\"\"\"\n",
    "    \n",
    "    data = np.genfromtxt(filename, names=True, delimiter=',')\n",
    "    \n",
    "    dates = np.array(\n",
    "        [datetime.datetime(int(data['year'][i]), int(data['month'][i]), int(data['day'][i]))\n",
    "         for i in range(data['value'].shape[0])])\n",
    "    \n",
    "    da = xr.DataArray(data['value'], coords={time_name: dates}, dims=[time_name])\n",
    "    \n",
    "    ds = da.to_dataset(name='index')\n",
    "    ds.attrs['source_file'] = filename\n",
    "    \n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_index_to_csv(output_file, index_da, header_attrs=None, time_name=None):\n",
    "    \"\"\"Write index data to CSV file.\"\"\"\n",
    "    \n",
    "    time_name = time_name if time_name is not None else rdu.get_time_name(index_da)\n",
    "    \n",
    "    df = pd.DataFrame({'value': index_da.data}, index=index_da[time_name].data)\n",
    "    \n",
    "    body = df.to_csv(index_label='date')\n",
    "    \n",
    "    if header_attrs is not None:\n",
    "        header = '\\n'.join('# {}: {}'.format(h, header_attrs[h]) for h in header_attrs)\n",
    "        body = '\\n'.join([header, body])\n",
    "        \n",
    "    with open(output_file, 'w') as ofs:\n",
    "        ofs.write(body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_index_nc_file(reanalysis, index, index_ds, base_period=BASE_PERIOD,\n",
    "                        frequency='daily', output_dir=None):\n",
    "    \"\"\"Write index data to netCDF file.\"\"\"\n",
    "    \n",
    "    if output_dir is None:\n",
    "        output_dir = get_reanalysis_indices_nc_dir(reanalysis)\n",
    "\n",
    "    output_file = get_index_datafile_name(\n",
    "        reanalysis, index, base_period=base_period, frequency=frequency,\n",
    "        ext='nc')\n",
    "\n",
    "    output_file = os.path.join(output_dir, output_file)\n",
    "    \n",
    "    index_ds.to_netcdf(output_file)\n",
    "    \n",
    "    return output_file\n",
    "    \n",
    "    \n",
    "def write_index_csv_file(reanalysis, index, index_ds, index_var,\n",
    "                         base_period=BASE_PERIOD, frequency='daily',\n",
    "                         output_dir=None, time_name=None):\n",
    "    \"\"\"Write index data to CSV file.\"\"\"\n",
    "    \n",
    "    if output_dir is None:\n",
    "        output_dir = get_reanalysis_indices_csv_dir(reanalysis)\n",
    "\n",
    "    output_file = get_index_datafile_name(\n",
    "        reanalysis, index, base_period=base_period, frequency=frequency,\n",
    "        ext='csv')\n",
    "\n",
    "    output_file = os.path.join(output_dir, output_file)\n",
    "    \n",
    "    header_attrs = {attr: index_ds.attrs[attr] for attr in index_ds.attrs}\n",
    "    \n",
    "    write_index_to_csv(output_file, index_ds[index_var], header_attrs=header_attrs,\n",
    "                       time_name=time_name)\n",
    "    \n",
    "    return output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def propagate_missing_values_through_time(da, time_name=None):\n",
    "    \"\"\"Propagate any missing values at one time to all times.\"\"\"\n",
    "    \n",
    "    time_name = time_name if time_name is not None else rdu.get_time_name(da)\n",
    "    \n",
    "    feature_dims = [d for d in da.dims if d != time_name]\n",
    "    original_shape = [da.sizes[d] for d in feature_dims]\n",
    "    \n",
    "    n_samples = da.sizes[time_name]\n",
    "    n_features = np.prod(original_shape)\n",
    "    \n",
    "    if da.get_axis_num(time_name) != 0:\n",
    "        da = da.transpose(*([time_name] + feature_dims))\n",
    "        \n",
    "    filled_data = np.reshape(da.data, (n_samples, n_features)).copy()\n",
    "    \n",
    "    points_to_fill = np.any(np.logical_not(np.isfinite(filled_data)), axis=0)\n",
    "    \n",
    "    if not np.any(points_to_fill):\n",
    "        return da\n",
    "    \n",
    "    filled_data[:, points_to_fill] = np.NaN\n",
    "    \n",
    "    filled_da = xr.DataArray(\n",
    "        filled_data.reshape([n_samples] + original_shape),\n",
    "        coords=da.coords, dims=da.dims)\n",
    "    \n",
    "    return filled_da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_indices_timeseries(indices_to_plot, years_per_row=10, points=False, time_name='time'):\n",
    "    \"\"\"Plot time-series of indices.\"\"\"\n",
    "    \n",
    "    start_date = None\n",
    "    end_date = None\n",
    "    index_min = np.inf\n",
    "    index_max = -np.inf\n",
    "    for index in indices_to_plot:\n",
    "        index_start_date = indices_to_plot[index][time_name].min().values\n",
    "        index_end_date = indices_to_plot[index][time_name].max().values\n",
    "        \n",
    "        if start_date is None or index_start_date < start_date:\n",
    "            start_date = index_start_date\n",
    "            \n",
    "        if end_date is None or index_end_date > end_date:\n",
    "            end_date = index_end_date\n",
    "            \n",
    "        if indices_to_plot[index].min().item() < index_min:\n",
    "            index_min = indices_to_plot[index].min().item()\n",
    "            \n",
    "        if indices_to_plot[index].max().item() > index_max:\n",
    "            index_max = indices_to_plot[index].max().item()\n",
    "            \n",
    "    start_year = pd.to_datetime(start_date).year\n",
    "    end_year = pd.to_datetime(end_date).year\n",
    "    n_years = end_year - start_year + 1\n",
    "    n_rows = int(np.ceil(n_years / years_per_row))\n",
    "    \n",
    "    fig = plt.figure(figsize=(15, 3 * n_rows))\n",
    "    gs = gridspec.GridSpec(nrows=n_rows, ncols=1, hspace=0.15)\n",
    "    \n",
    "    for i in range(n_rows):\n",
    "        \n",
    "        ax = fig.add_subplot(gs[i, 0])\n",
    "\n",
    "        row_start_year = start_year + i * years_per_row\n",
    "        row_end_year = start_year + (i + 1) * years_per_row - 1\n",
    "        \n",
    "        row_start_date = np.datetime64('{:d}-01-01'.format(row_start_year))\n",
    "        row_end_date = np.datetime64('{:d}-12-31'.format(row_end_year))\n",
    "        \n",
    "        markers = itertools.cycle(('.', 'x', 's', '+', 'd'))\n",
    "        colors = itertools.cycle(('r', 'b', 'g', 'y', 'k'))\n",
    "        styles = itertools.cycle(('-', '--', ':', '-.'))\n",
    "        \n",
    "        for index in indices_to_plot:\n",
    "            \n",
    "            index_data = indices_to_plot[index]\n",
    "            index_data = index_data.where(\n",
    "                (index_data[time_name] >= row_start_date) &\n",
    "                (index_data[time_name] <= row_end_date), drop=True)\n",
    "            \n",
    "            marker = next(markers)\n",
    "            color = next(colors)\n",
    "            style = next(styles)\n",
    "\n",
    "            if points:\n",
    "                ax.plot(index_data[time_name], index_data.data, color=color, marker=marker,\n",
    "                        ls='none', label=index)\n",
    "            else:\n",
    "                ax.plot(index_data[time_name], index_data.data, color=color, ls=style,\n",
    "                        label=index)\n",
    "            \n",
    "        ax.grid(ls='--', color='gray', alpha=0.5)\n",
    "        \n",
    "        ax.set_xlim(row_start_date, row_end_date)\n",
    "        ax.set_ylim(index_min, index_max)\n",
    "\n",
    "        ax.tick_params(which='both', labelsize=13)\n",
    "        ax.set_xlabel('Date', fontsize=14)\n",
    "        ax.set_ylabel('Index value', fontsize=14)\n",
    "            \n",
    "        if i == 0:\n",
    "            ax.legend(fontsize=13)\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_files = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 500 hPa geopotential height indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reanalysis_h500_variable(reanalysis):\n",
    "    \"\"\"Get name of reanalysis 500 hPa geopotential height field.\"\"\"\n",
    "    \n",
    "    if reanalysis == 'nnr1':\n",
    "        return 'hgt'\n",
    "    \n",
    "    if reanalysis == 'jra55':\n",
    "        return 'HGT_GDS0_ISBL'\n",
    "    \n",
    "    raise ValueError(\"Unrecognized reanalysis '%r'\" % reanalysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ao_indices(hgt_da, reanalysis, input_file=None,\n",
    "                         eofs_output_dir=None, indices_csv_output_dir=None,\n",
    "                         indices_nc_output_dir=None,\n",
    "                         ao_mode=0, base_period=BASE_PERIOD,\n",
    "                         lat_name=None, lon_name=None, time_name=None):\n",
    "    \"\"\"Calculate monthly and daily AO indices.\"\"\"\n",
    "    \n",
    "    # Calculate daily and monthly indices.\n",
    "    ao_loadings_ds, daily_index_ds = rdi.pc_ao(\n",
    "        hgt_da, frequency='daily', base_period=base_period, ao_mode=ao_mode)\n",
    "    _, monthly_index_ds = rdi.pc_ao(\n",
    "        hgt_da, frequency='monthly', base_period=base_period, ao_mode=ao_mode)\n",
    "    \n",
    "    if input_file is not None:\n",
    "        ao_loadings_ds.attrs['input_file'] = input_file\n",
    "        daily_index_ds.attrs['input_file'] = input_file\n",
    "        monthly_index_ds.attrs['input_file'] = input_file\n",
    "\n",
    "    # Write loading pattern to file.\n",
    "    base_period_str = get_timespan_string(base_period)\n",
    "    \n",
    "    if eofs_output_dir is None:\n",
    "        eofs_output_dir = get_reanalysis_eofs_nc_dir(reanalysis)\n",
    "        \n",
    "    eofs_output_file = '.'.join(\n",
    "        [reanalysis, base_period_str, 'ao', 'monthly', 'eofs', 'nc'])\n",
    "    eofs_output_file = os.path.join(eofs_output_dir, eofs_output_file)\n",
    "        \n",
    "    ao_loadings_ds.to_netcdf(eofs_output_file)\n",
    "\n",
    "    # Write daily index to file.        \n",
    "    daily_index_nc_output_file = write_index_nc_file(\n",
    "        reanalysis, 'ao', daily_index_ds, base_period=base_period,\n",
    "        frequency='daily', output_dir=indices_nc_output_dir)\n",
    "    daily_index_csv_output_file = write_index_csv_file(\n",
    "        reanalysis, 'ao', daily_index_ds, 'ao_index',\n",
    "        base_period=base_period,\n",
    "        frequency='daily', output_dir=indices_csv_output_dir)\n",
    "    \n",
    "    # Write monthly index to file.        \n",
    "    monthly_index_nc_output_file = write_index_nc_file(\n",
    "        reanalysis, 'ao', monthly_index_ds, base_period=base_period,\n",
    "        frequency='monthly', output_dir=indices_nc_output_dir)\n",
    "    monthly_index_csv_output_file = write_index_csv_file(\n",
    "        reanalysis, 'ao', monthly_index_ds, 'ao_index',\n",
    "        base_period=base_period,\n",
    "        frequency='monthly', output_dir=indices_csv_output_dir)\n",
    "    \n",
    "    return {'eofs_nc': eofs_output_file,\n",
    "            'daily_index_nc': daily_index_nc_output_file,\n",
    "            'daily_index_csv': daily_index_csv_output_file,\n",
    "            'monthly_index_nc': monthly_index_nc_output_file,\n",
    "            'monthly_index_csv': monthly_index_csv_output_file}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_nhtele_indices(hgt_da, reanalysis, input_file=None,\n",
    "                             composites_output_dir=None, indices_csv_output_dir=None,\n",
    "                             indices_nc_output_dir=None,\n",
    "                             base_period=BASE_PERIOD,\n",
    "                             lat_name=None, lon_name=None, time_name=None):\n",
    "    \"\"\"Calculate monthly and daily NHTELE indices.\"\"\"\n",
    "    \n",
    "    window_length = 10\n",
    "    n_modes = 24\n",
    "    n_clusters = 4\n",
    "    season = 'DJF'\n",
    "    \n",
    "    daily_indices_ds = rdi.kmeans_pcs(\n",
    "        hgt_da, frequency='daily', base_period=base_period,\n",
    "        window_length=window_length, n_modes=n_modes, n_clusters=n_clusters,\n",
    "        season=season)\n",
    "    monthly_indices_ds = rdi.kmeans_pcs(\n",
    "        hgt_da, frequency='monthly', base_period=base_period,\n",
    "        window_length=window_length, n_modes=n_modes, n_clusters=n_clusters,\n",
    "        season=season)\n",
    "    \n",
    "    if input_file is not None:\n",
    "        daily_indices_ds.attrs['input_file'] = input_file\n",
    "        monthly_indices_ds.attrs['input_file'] = input_file\n",
    "        \n",
    "    # Write composites to file.\n",
    "    base_period_str = get_timespan_string(base_period)\n",
    "    \n",
    "    if composites_output_dir is None:\n",
    "        composites_output_dir = get_reanalysis_eofs_nc_dir(reanalysis)\n",
    "        \n",
    "    composites_output_file = '.'.join(\n",
    "        [reanalysis, base_period_str, 'nhtele', 'daily', 'composites', 'nc'])\n",
    "    composites_output_file = os.path.join(\n",
    "        composites_output_dir, composites_output_file)\n",
    "\n",
    "    composites_ds = daily_indices_ds['composites'].to_dataset(name='composites')\n",
    "    for attr in daily_indices_ds.attrs:\n",
    "        composites_ds.attrs[attr] = daily_indices_ds.attrs[attr]\n",
    "        \n",
    "    composites_ds.to_netcdf(composites_output_file)\n",
    "    \n",
    "    output_files = {'composites_nc': composites_output_file}\n",
    "\n",
    "    # Write indices to file.\n",
    "    for i in range(n_clusters):\n",
    "        \n",
    "        index_name = 'nhtele{:d}'.format(i + 1)\n",
    "        \n",
    "        daily_index_ds = daily_indices_ds['indices'].sel(cluster=i).squeeze().to_dataset(\n",
    "            name=index_name)\n",
    "        for attr in daily_indices_ds.attrs:\n",
    "            daily_index_ds.attrs[attr] = daily_indices_ds.attrs[attr]\n",
    "            \n",
    "        monthly_index_ds = monthly_indices_ds['indices'].sel(cluster=i).squeeze().to_dataset(\n",
    "            name=index_name)\n",
    "        for attr in monthly_indices_ds.attrs:\n",
    "            monthly_index_ds.attrs[attr] = monthly_indices_ds.attrs[attr]\n",
    "\n",
    "        # Write daily index to file.\n",
    "        daily_index_nc_output_file = write_index_nc_file(\n",
    "            reanalysis, index_name, daily_index_ds, base_period=base_period,\n",
    "            frequency='daily', output_dir=indices_nc_output_dir)\n",
    "        daily_index_csv_output_file = write_index_csv_file(\n",
    "            reanalysis, index_name, daily_index_ds, index_name,\n",
    "            base_period=base_period,\n",
    "            frequency='daily', output_dir=indices_csv_output_dir)\n",
    "        \n",
    "        # Write monthly index to file.\n",
    "        monthly_index_nc_output_file = write_index_nc_file(\n",
    "            reanalysis, index_name, monthly_index_ds, base_period=base_period,\n",
    "            frequency='monthly', output_dir=indices_nc_output_dir)\n",
    "        monthly_index_csv_output_file = write_index_csv_file(\n",
    "            reanalysis, index_name, monthly_index_ds, index_name,\n",
    "            base_period=base_period,\n",
    "            frequency='monthly', output_dir=indices_csv_output_dir)\n",
    "        \n",
    "        output_files['daily_{}_nc'.format(index_name)] = daily_index_nc_output_file\n",
    "        output_files['daily_{}_csv'.format(index_name)] = daily_index_csv_output_file\n",
    "        output_files['monthly_{}_nc'.format(index_name)] = monthly_index_nc_output_file\n",
    "        output_files['monthly_{}_csv'.format(index_name)] = monthly_index_csv_output_file\n",
    "\n",
    "    return output_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_pna_indices(hgt_da, reanalysis, input_file=None,\n",
    "                          eofs_output_dir=None, indices_csv_output_dir=None,\n",
    "                          indices_nc_output_dir=None, pna_mode=0,\n",
    "                          base_period=BASE_PERIOD,\n",
    "                          lat_name=None, lon_name=None, time_name=None):\n",
    "    \"\"\"Calculate monthly and daily PNA indices.\"\"\"\n",
    "    \n",
    "    n_modes = 10\n",
    "\n",
    "    # Calculate daily and monthly indices.\n",
    "    pna_loadings_ds, daily_index_ds = rdi.pc_pna(\n",
    "        hgt_da, frequency='daily', base_period=base_period,\n",
    "        pna_mode=pna_mode, n_modes=n_modes)\n",
    "    _, monthly_index_ds = rdi.pc_pna(\n",
    "        hgt_da, frequency='monthly', base_period=base_period,\n",
    "        pna_mode=pna_mode, n_modes=n_modes)\n",
    "    \n",
    "    if input_file is not None:\n",
    "        pna_loadings_ds.attrs['input_file'] = input_file\n",
    "        daily_index_ds.attrs['input_file'] = input_file\n",
    "        monthly_index_ds.attrs['input_file'] = input_file\n",
    "        \n",
    "    # Write loading patterns to file.\n",
    "    base_period_str = get_timespan_string(base_period)\n",
    "    \n",
    "    if eofs_output_dir is None:\n",
    "        eofs_output_dir = get_reanalysis_eofs_nc_dir(reanalysis)\n",
    "        \n",
    "    eofs_output_file = '.'.join(\n",
    "        [reanalysis, base_period_str, 'pna', 'monthly', 'eofs', 'nc'])\n",
    "    eofs_output_file = os.path.join(eofs_output_dir, eofs_output_file)\n",
    "\n",
    "    pna_loadings_ds.to_netcdf(eofs_output_file)\n",
    "    \n",
    "    # Write daily index to file.        \n",
    "    daily_index_nc_output_file = write_index_nc_file(\n",
    "        reanalysis, 'pna', daily_index_ds, base_period=base_period,\n",
    "        frequency='daily', output_dir=indices_nc_output_dir)\n",
    "    daily_index_csv_output_file = write_index_csv_file(\n",
    "        reanalysis, 'pna', daily_index_ds, 'pna_index',\n",
    "        base_period=base_period,\n",
    "        frequency='daily', output_dir=indices_csv_output_dir)\n",
    "    \n",
    "    # Write monthly index to file.        \n",
    "    monthly_index_nc_output_file = write_index_nc_file(\n",
    "        reanalysis, 'pna', monthly_index_ds, base_period=base_period,\n",
    "        frequency='monthly', output_dir=indices_nc_output_dir)\n",
    "    monthly_index_csv_output_file = write_index_csv_file(\n",
    "        reanalysis, 'pna', monthly_index_ds, 'pna_index',\n",
    "        base_period=base_period,\n",
    "        frequency='monthly', output_dir=indices_csv_output_dir)\n",
    "    \n",
    "    return {'eofs_nc': eofs_output_file,\n",
    "            'daily_index_nc': daily_index_nc_output_file,\n",
    "            'daily_index_csv': daily_index_csv_output_file,\n",
    "            'monthly_index_nc': monthly_index_nc_output_file,\n",
    "            'monthly_index_csv': monthly_index_csv_output_file}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_psa_indices(hgt_da, reanalysis, input_file=None,\n",
    "                          eofs_output_dir=None, indices_csv_output_dir=None,\n",
    "                          indices_nc_output_dir=None, psa1_mode=1, psa2_mode=2,\n",
    "                          base_period=BASE_PERIOD,\n",
    "                          lat_name=None, lon_name=None, time_name=None):\n",
    "    \"\"\"Calculate monthly and daily PSA indices.\"\"\"\n",
    "    \n",
    "    # Calculate daily and monthly indices.\n",
    "    psa_loadings_ds, daily_indices_ds = rdi.real_pc_psa(\n",
    "        hgt_da, frequency='daily', base_period=base_period,\n",
    "        psa1_mode=psa1_mode, psa2_mode=psa2_mode, rotate=False,\n",
    "        eofs_season='ALL', eofs_frequency='daily')\n",
    "    _, monthly_indices_ds = rdi.real_pc_psa(\n",
    "        hgt_da, frequency='monthly', base_period=base_period,\n",
    "        psa1_mode=psa1_mode, psa2_mode=psa2_mode, rotate=False,\n",
    "        eofs_season='ALL', eofs_frequency='daily')\n",
    "    \n",
    "    if input_file is not None:\n",
    "        psa_loadings_ds.attrs['input_file'] = input_file\n",
    "        daily_indices_ds.attrs['input_file'] = input_file\n",
    "        monthly_indices_ds.attrs['input_file'] = input_file\n",
    "        \n",
    "    # Write loading patterns to file.\n",
    "    base_period_str = get_timespan_string(base_period)\n",
    "    \n",
    "    if eofs_output_dir is None:\n",
    "        eofs_output_dir = get_reanalysis_eofs_nc_dir(reanalysis)\n",
    "        \n",
    "    eofs_output_file = '.'.join(\n",
    "        [reanalysis, base_period_str, 'psa', 'daily', 'eofs', 'nc'])\n",
    "    eofs_output_file = os.path.join(eofs_output_dir, eofs_output_file)\n",
    "\n",
    "    psa_loadings_ds.to_netcdf(eofs_output_file)\n",
    "    \n",
    "    output_files = {'eofs_nc': eofs_output_file}\n",
    "\n",
    "    # Write indices to file.\n",
    "    for i in (1, 2):\n",
    "        \n",
    "        index_name = 'psa{:d}_index'.format(i)\n",
    "        \n",
    "        daily_index_ds = daily_indices_ds[index_name].to_dataset(name=index_name)\n",
    "        monthly_index_ds = monthly_indices_ds[index_name].to_dataset(name=index_name)\n",
    "        \n",
    "        for attr in daily_indices_ds.attrs:\n",
    "            daily_index_ds.attrs[attr] = daily_indices_ds.attrs[attr]\n",
    "            \n",
    "        for attr in monthly_indices_ds.attrs:\n",
    "            monthly_index_ds.attrs[attr] = monthly_indices_ds.attrs[attr]\n",
    "        \n",
    "        # Write daily index to file.\n",
    "        daily_index_nc_output_file = write_index_nc_file(\n",
    "            reanalysis, index_name, daily_index_ds, base_period=base_period,\n",
    "            frequency='daily', output_dir=indices_nc_output_dir)\n",
    "        daily_index_csv_output_file = write_index_csv_file(\n",
    "            reanalysis, index_name, daily_index_ds, index_name,\n",
    "            base_period=base_period,\n",
    "            frequency='daily', output_dir=indices_csv_output_dir)\n",
    "        \n",
    "        # Write monthly index to file.\n",
    "        monthly_index_nc_output_file = write_index_nc_file(\n",
    "            reanalysis, index_name, monthly_index_ds, base_period=base_period,\n",
    "            frequency='monthly', output_dir=indices_nc_output_dir)\n",
    "        monthly_index_csv_output_file = write_index_csv_file(\n",
    "            reanalysis, index_name, monthly_index_ds, index_name,\n",
    "            base_period=base_period,\n",
    "            frequency='monthly', output_dir=indices_csv_output_dir)\n",
    "        \n",
    "        output_files['daily_{}_nc'.format(index_name)] = daily_index_nc_output_file\n",
    "        output_files['daily_{}_csv'.format(index_name)] = daily_index_csv_output_file\n",
    "        output_files['monthly_{}_nc'.format(index_name)] = monthly_index_nc_output_file\n",
    "        output_files['monthly_{}_csv'.format(index_name)] = monthly_index_csv_output_file\n",
    "        \n",
    "    return output_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sam_indices(hgt_da, reanalysis, input_file=None,\n",
    "                          eofs_output_dir=None, indices_csv_output_dir=None,\n",
    "                          indices_nc_output_dir=None,\n",
    "                          sam_mode=0, base_period=BASE_PERIOD,\n",
    "                          lat_name=None, lon_name=None, time_name=None):\n",
    "    \"\"\"Calculate monthly and daily SAM indices.\"\"\"\n",
    "    \n",
    "    # Calculate daily and monthly indices.\n",
    "    sam_loadings_ds, daily_index_ds = rdi.pc_sam(\n",
    "        hgt_da, frequency='daily', base_period=base_period, sam_mode=sam_mode)\n",
    "    _, monthly_index_ds = rdi.pc_sam(\n",
    "        hgt_da, frequency='monthly', base_period=base_period, sam_mode=sam_mode)\n",
    "    \n",
    "    if input_file is not None:\n",
    "        sam_loadings_ds.attrs['input_file'] = input_file\n",
    "        daily_index_ds.attrs['input_file'] = input_file\n",
    "        monthly_index_ds.attrs['input_file'] = input_file\n",
    "\n",
    "    # Write loading pattern to file.\n",
    "    base_period_str = get_timespan_string(base_period)\n",
    "    \n",
    "    if eofs_output_dir is None:\n",
    "        eofs_output_dir = get_reanalysis_eofs_nc_dir(reanalysis)\n",
    "        \n",
    "    eofs_output_file = '.'.join(\n",
    "        [reanalysis, base_period_str, 'sam', 'monthly', 'eofs', 'nc'])\n",
    "    eofs_output_file = os.path.join(eofs_output_dir, eofs_output_file)\n",
    "        \n",
    "    sam_loadings_ds.to_netcdf(eofs_output_file)\n",
    "\n",
    "    # Write daily index to file.        \n",
    "    daily_index_nc_output_file = write_index_nc_file(\n",
    "        reanalysis, 'sam', daily_index_ds, base_period=base_period,\n",
    "        frequency='daily', output_dir=indices_nc_output_dir)\n",
    "    daily_index_csv_output_file = write_index_csv_file(\n",
    "        reanalysis, 'sam', daily_index_ds, 'sam_index',\n",
    "        base_period=base_period,\n",
    "        frequency='daily', output_dir=indices_csv_output_dir)\n",
    "    \n",
    "    # Write monthly index to file.        \n",
    "    monthly_index_nc_output_file = write_index_nc_file(\n",
    "        reanalysis, 'sam', monthly_index_ds, base_period=base_period,\n",
    "        frequency='monthly', output_dir=indices_nc_output_dir)\n",
    "    monthly_index_csv_output_file = write_index_csv_file(\n",
    "        reanalysis, 'sam', monthly_index_ds, 'sam_index',\n",
    "        base_period=base_period,\n",
    "        frequency='monthly', output_dir=indices_csv_output_dir)\n",
    "    \n",
    "    return {'eofs_nc': eofs_output_file,\n",
    "            'daily_index_nc': daily_index_nc_output_file,\n",
    "            'daily_index_csv': daily_index_csv_output_file,\n",
    "            'monthly_index_nc': monthly_index_nc_output_file,\n",
    "            'monthly_index_csv': monthly_index_csv_output_file}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h500_input_files = {\n",
    "    'jra55': os.path.join(get_reanalysis_fields_dir('jra55'), 'jra.55.hgt.500.1958010100_2018123118.nc'),\n",
    "    'nnr1': os.path.join(get_reanalysis_fields_dir('nnr1'), 'nnr1.hgt.500.19480101_20200530.nc')\n",
    "}\n",
    "\n",
    "for reanalysis in h500_input_files:\n",
    "    \n",
    "    print('* Reanalysis: ', reanalysis)\n",
    "\n",
    "    eofs_output_dir = get_reanalysis_eofs_nc_dir(reanalysis)\n",
    "    if not os.path.exists(eofs_output_dir):\n",
    "        os.makedirs(eofs_output_dir)\n",
    "        \n",
    "    indices_nc_output_dir = get_reanalysis_indices_nc_dir(reanalysis)\n",
    "    if not os.path.exists(indices_nc_output_dir):\n",
    "        os.makedirs(indices_nc_output_dir)\n",
    "        \n",
    "    indices_csv_output_dir = get_reanalysis_indices_csv_dir(reanalysis)\n",
    "    if not os.path.exists(indices_csv_output_dir):\n",
    "        os.makedirs(indices_csv_output_dir)\n",
    "\n",
    "    output_files[reanalysis] = {}\n",
    "\n",
    "    hgt_var = get_reanalysis_h500_variable(reanalysis)\n",
    "\n",
    "    input_file = h500_input_files[reanalysis]\n",
    "    with xr.open_dataset(input_file) as ds:\n",
    "        \n",
    "        print('\\t- Preparing data ...', end='')\n",
    "\n",
    "        start_time = time.perf_counter()\n",
    "\n",
    "        # Extract height data.\n",
    "        hgt_da = ds[hgt_var].squeeze()\n",
    "\n",
    "        # Restrict to common time-period and ensure fixed missing\n",
    "        # values, if present.\n",
    "        time_name = rdu.get_time_name(hgt_da)\n",
    "        hgt_da = hgt_da.where(hgt_da[time_name].dt.year >= START_YEAR,\n",
    "                              drop=True)\n",
    "        \n",
    "        hgt_da = propagate_missing_values_through_time(\n",
    "            hgt_da, time_name=time_name)\n",
    "        \n",
    "        # Normalize start times.\n",
    "        input_frequency = rdu.detect_frequency(hgt_da, time_name=time_name)\n",
    "        \n",
    "        if input_frequency == 'daily':\n",
    "            hgt_da = hgt_da.resample({time_name: '1D'}).mean(time_name)\n",
    "        elif input_frequency == 'monthly':\n",
    "            hgt_da = hgt_da.resample({time_name: '1MS'}).mean(time_name)\n",
    "        else:\n",
    "            raise RuntimeError('Could not determine input frequency')\n",
    "        \n",
    "        end_time = time.perf_counter()\n",
    "        print(' (time: {:.2f}s)'.format(end_time - start_time))\n",
    "\n",
    "        print('\\t- AO ...', end='')\n",
    "        start_time = time.perf_counter()\n",
    "        output_files[reanalysis]['AO'] = calculate_ao_indices(\n",
    "            hgt_da, reanalysis, input_file=input_file)\n",
    "        end_time = time.perf_counter()\n",
    "        print(' (time: {:.2f}s)'.format(end_time - start_time))\n",
    "        \n",
    "        print('\\t- NHTELE ...', end='')\n",
    "        start_time = time.perf_counter()\n",
    "        output_files[reanalysis]['NHTELE'] = calculate_nhtele_indices(\n",
    "            hgt_da, reanalysis, input_file=input_file)\n",
    "        end_time = time.perf_counter()\n",
    "        print(' (time: {:.2f}s)'.format(end_time - start_time))\n",
    "\n",
    "        print('\\t- PNA ...', end='')\n",
    "        start_time = time.perf_counter()\n",
    "        output_files[reanalysis]['PNA'] = calculate_pna_indices(\n",
    "            hgt_da, reanalysis, input_file=input_file)\n",
    "        end_time = time.perf_counter()\n",
    "        print(' (time: {:.2f}s)'.format(end_time - start_time))\n",
    "        \n",
    "        print('\\t- PSA ...', end='')\n",
    "        start_time = time.perf_counter()\n",
    "        output_files[reanalysis]['PSA'] = calculate_psa_indices(\n",
    "            hgt_da, reanalysis, input_file=input_file)\n",
    "        end_time = time.perf_counter()\n",
    "        print(' (time: {:.2f}s)'.format(end_time - start_time))\n",
    "        \n",
    "        print('\\t- SAM ...', end='')\n",
    "        start_time = time.perf_counter()\n",
    "        output_files[reanalysis]['SAM'] = calculate_sam_indices(\n",
    "            hgt_da, reanalysis, input_file=input_file)\n",
    "        end_time = time.perf_counter()\n",
    "        print(' (time: {:.2f}s)'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SST indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reanalysis_sst_variable(reanalysis):\n",
    "    \"\"\"Get name of reanalysis SST field.\"\"\"\n",
    "    \n",
    "    if reanalysis in ('hadisst', 'nnr1'):\n",
    "        return 'sst'\n",
    "    \n",
    "    if reanalysis == 'jra55':\n",
    "        return 'BRTMP_GDS0_SFC'\n",
    "    \n",
    "    raise ValueError(\"Unrecognized reanalysis '%r'\" % reanalysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_indopacific_indices(sst_da, reanalysis, input_file=None,\n",
    "                                  eofs_output_dir=None, indices_csv_output_dir=None,\n",
    "                                  indices_nc_output_dir=None,\n",
    "                                  base_period=BASE_PERIOD,\n",
    "                                  lat_name=None, lon_name=None, time_name=None):\n",
    "    \"\"\"Calculate monthly Indopacific SST indices.\"\"\"\n",
    "    \n",
    "    # Calculate monthly index.\n",
    "    loadings_ds, monthly_indices_ds = rdi.dc_sst(\n",
    "        sst_da, frequency='monthly', base_period=base_period,\n",
    "        lat_name=lat_name, lon_name=lon_name, time_name=time_name)\n",
    "\n",
    "    if input_file is not None:\n",
    "        loadings_ds.attrs['input_file'] = input_file\n",
    "        monthly_indices_ds.attrs['input_file'] = input_file\n",
    "\n",
    "    # Write EOFs to file.\n",
    "    base_period_str = get_timespan_string(base_period)\n",
    "    \n",
    "    if eofs_output_dir is None:\n",
    "        eofs_output_dir = get_reanalysis_eofs_nc_dir(reanalysis)\n",
    "        \n",
    "    eofs_output_file = '.'.join(\n",
    "        [reanalysis, base_period_str, 'dc_sst', 'monthly', 'eofs', 'nc'])\n",
    "    eofs_output_file = os.path.join(eofs_output_dir, eofs_output_file)\n",
    "        \n",
    "    loadings_ds.to_netcdf(eofs_output_file)\n",
    "\n",
    "    output_files = {'eofs_nc': eofs_output_file}\n",
    "\n",
    "    # Write monthly indices to file.\n",
    "    for index in ('sst1_index', 'sst2_index'):\n",
    "        \n",
    "        monthly_index_ds = monthly_indices_ds[index].to_dataset(name=index)\n",
    "        \n",
    "        for attr in monthly_indices_ds.attrs:\n",
    "            monthly_index_ds.attrs[attr] = monthly_indices_ds.attrs[attr]\n",
    "        \n",
    "        # Write monthly index to file.\n",
    "        monthly_index_nc_output_file = write_index_nc_file(\n",
    "            reanalysis, index, monthly_index_ds, base_period=base_period,\n",
    "            frequency='monthly', output_dir=indices_nc_output_dir)\n",
    "        monthly_index_csv_output_file = write_index_csv_file(\n",
    "            reanalysis, index, monthly_index_ds, index,\n",
    "            base_period=base_period,\n",
    "            frequency='monthly', output_dir=indices_csv_output_dir)\n",
    "        \n",
    "        output_files['monthly_{}_nc'.format(index)] = monthly_index_nc_output_file\n",
    "        output_files['monthly_{}_csv'.format(index)] = monthly_index_csv_output_file\n",
    "        \n",
    "    return output_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_iod_indices(sst_da, reanalysis, input_file=None,\n",
    "                          eofs_output_dir=None, indices_csv_output_dir=None,\n",
    "                          indices_nc_output_dir=None,\n",
    "                          base_period=BASE_PERIOD,\n",
    "                          lat_name=None, lon_name=None, time_name=None):\n",
    "    \"\"\"Calculate monthly and daily IOD indices.\"\"\"\n",
    "    \n",
    "    # Calculate daily and monthly indices.\n",
    "    daily_index_da = rdi.dmi(\n",
    "        sst_da, frequency='daily', base_period=base_period,\n",
    "        lat_name=lat_name, lon_name=lon_name, time_name=time_name)\n",
    "    monthly_index_da = rdi.dmi(\n",
    "        sst_da, frequency='monthly', base_period=base_period,\n",
    "        lat_name=lat_name, lon_name=lon_name, time_name=time_name)\n",
    "    weekly_index_da = rdi.dmi(\n",
    "        sst_da, frequency='weekly', base_period=base_period,\n",
    "        lat_name=lat_name, lon_name=lon_name, time_name=time_name)\n",
    "    \n",
    "    daily_index_ds = daily_index_da.to_dataset(name='dmi')\n",
    "    for attr in daily_index_da.attrs:\n",
    "        daily_index_ds.attrs[attr] = daily_index_da.attrs[attr]\n",
    "\n",
    "    monthly_index_ds = monthly_index_da.to_dataset(name='dmi')\n",
    "    for attr in monthly_index_da.attrs:\n",
    "        monthly_index_ds.attrs[attr] = monthly_index_da.attrs[attr]\n",
    "\n",
    "    weekly_index_ds = weekly_index_da.to_dataset(name='dmi')\n",
    "    for attr in weekly_index_da.attrs:\n",
    "        weekly_index_ds.attrs[attr] = weekly_index_da.attrs[attr]\n",
    "\n",
    "    if input_file is not None:\n",
    "        daily_index_ds.attrs['input_file'] = input_file\n",
    "        monthly_index_ds.attrs['input_file'] = input_file\n",
    "        weekly_index_ds.attrs['input_file'] = input_file\n",
    "\n",
    "    # Write daily index to file.        \n",
    "    daily_index_nc_output_file = write_index_nc_file(\n",
    "        reanalysis, 'dmi', daily_index_ds, base_period=base_period,\n",
    "        frequency='daily', output_dir=indices_nc_output_dir)\n",
    "    daily_index_csv_output_file = write_index_csv_file(\n",
    "        reanalysis, 'dmi', daily_index_ds, 'dmi',\n",
    "        base_period=base_period,\n",
    "        frequency='daily', output_dir=indices_csv_output_dir)\n",
    "    \n",
    "    # Write monthly index to file.        \n",
    "    monthly_index_nc_output_file = write_index_nc_file(\n",
    "        reanalysis, 'dmi', monthly_index_ds, base_period=base_period,\n",
    "        frequency='monthly', output_dir=indices_nc_output_dir)\n",
    "    monthly_index_csv_output_file = write_index_csv_file(\n",
    "        reanalysis, 'dmi', monthly_index_ds, 'dmi',\n",
    "        base_period=base_period,\n",
    "        frequency='monthly', output_dir=indices_csv_output_dir)\n",
    "    \n",
    "    # Write weekly index to file.        \n",
    "    weekly_index_nc_output_file = write_index_nc_file(\n",
    "        reanalysis, 'dmi', weekly_index_ds, base_period=base_period,\n",
    "        frequency='weekly', output_dir=indices_nc_output_dir)\n",
    "    weekly_index_csv_output_file = write_index_csv_file(\n",
    "        reanalysis, 'dmi', weekly_index_ds, 'dmi',\n",
    "        base_period=base_period,\n",
    "        frequency='weekly', output_dir=indices_csv_output_dir)\n",
    "\n",
    "    return {'daily_index_nc': daily_index_nc_output_file,\n",
    "            'daily_index_csv': daily_index_csv_output_file,\n",
    "            'monthly_index_nc': monthly_index_nc_output_file,\n",
    "            'monthly_index_csv': monthly_index_csv_output_file,\n",
    "            'weekly_index_nc': weekly_index_nc_output_file,\n",
    "            'weekly_index_csv': weekly_index_csv_output_file}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sst_input_files = {\n",
    "    'hadisst': os.path.join(get_reanalysis_fields_dir('hadisst'), 'HadISST_sst.nc'),\n",
    "    'jra55': os.path.join(get_reanalysis_fields_dir('jra55'), 'fcst_surf125.118_brtmp.1958010100_2018123100.daily.nc')\n",
    "}\n",
    "\n",
    "for reanalysis in sst_input_files:\n",
    "    \n",
    "    print('* Reanalysis: ', reanalysis)\n",
    "\n",
    "    eofs_output_dir = get_reanalysis_eofs_nc_dir(reanalysis)\n",
    "    if not os.path.exists(eofs_output_dir):\n",
    "        os.makedirs(eofs_output_dir)\n",
    "        \n",
    "    indices_nc_output_dir = get_reanalysis_indices_nc_dir(reanalysis)\n",
    "    if not os.path.exists(indices_nc_output_dir):\n",
    "        os.makedirs(indices_nc_output_dir)\n",
    "        \n",
    "    indices_csv_output_dir = get_reanalysis_indices_csv_dir(reanalysis)\n",
    "    if not os.path.exists(indices_csv_output_dir):\n",
    "        os.makedirs(indices_csv_output_dir)\n",
    "\n",
    "    sst_var = get_reanalysis_sst_variable(reanalysis)\n",
    "\n",
    "    input_file = sst_input_files[reanalysis]\n",
    "    with xr.open_dataset(input_file) as ds:\n",
    "        \n",
    "        print('\\t- Preparing data ...', end='')\n",
    "\n",
    "        if reanalysis not in output_files:\n",
    "            output_files[reanalysis] = {}\n",
    "\n",
    "        start_time = time.perf_counter()\n",
    "\n",
    "        # Extract SST data.\n",
    "        sst_da = ds[sst_var].squeeze()\n",
    "\n",
    "        # Restrict to common time-period and ensure fixed missing\n",
    "        # values, if present.\n",
    "        time_name = rdu.get_time_name(sst_da)\n",
    "        sst_da = sst_da.where(sst_da[time_name].dt.year >= START_YEAR,\n",
    "                              drop=True)\n",
    "        \n",
    "        sst_da = propagate_missing_values_through_time(\n",
    "            sst_da, time_name=time_name)\n",
    "        \n",
    "        # Normalize start times.\n",
    "        input_frequency = rdu.detect_frequency(sst_da, time_name=time_name)\n",
    "        \n",
    "        if input_frequency == 'daily':\n",
    "            sst_da = sst_da.resample({time_name: '1D'}).mean(time_name)\n",
    "        elif input_frequency == 'monthly':\n",
    "            sst_da = sst_da.resample({time_name: '1MS'}).mean(time_name)\n",
    "        else:\n",
    "            raise RuntimeError('Could not determine input frequency')\n",
    "        \n",
    "        end_time = time.perf_counter()\n",
    "        print(' (time: {:.2f}s)'.format(end_time - start_time))\n",
    "\n",
    "        print('\\t- Indopacific SST ...', end='')\n",
    "        start_time = time.perf_counter()\n",
    "        output_files[reanalysis]['DCSST'] = calculate_indopacific_indices(\n",
    "            sst_da, reanalysis, input_file=input_file)\n",
    "        end_time = time.perf_counter()\n",
    "        print(' (time: {:.2f}s)'.format(end_time - start_time))\n",
    "        \n",
    "        print('\\t- DMI ...', end='')\n",
    "        start_time = time.perf_counter()\n",
    "        output_files[reanalysis]['DMI'] = calculate_iod_indices(\n",
    "            sst_da, reanalysis, input_file=input_file)\n",
    "        end_time = time.perf_counter()\n",
    "        print(' (time: {:.2f}s)'.format(end_time - start_time))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MEI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reanalysis_olr_variable(reanalysis):\n",
    "    \"\"\"Get name of reanalysis OLR field.\"\"\"\n",
    "    \n",
    "    if reanalysis == 'jra55':\n",
    "        return 'ULWRF_GDS0_NTAT_ave3h'\n",
    "\n",
    "    if reanalysis == 'nnr1':\n",
    "        return 'ulwrf'\n",
    "    \n",
    "    raise ValueError(\"Unrecognized reanalysis '%r'\" % reanalysis)\n",
    "    \n",
    "\n",
    "def get_reanalysis_slp_variable(reanalysis):\n",
    "    \"\"\"Get name of reanalysis SLP field.\"\"\"\n",
    "\n",
    "    if reanalysis == 'jra55':\n",
    "        return 'PRMSL_GDS0_MSL'\n",
    "\n",
    "    if reanalysis == 'nnr1':\n",
    "        return 'slp'\n",
    "    \n",
    "    raise ValueError(\"Unrecognized reanalysis '%r'\" % reanalysis)\n",
    "    \n",
    "    \n",
    "def get_reanalysis_usfc_variable(reanalysis):\n",
    "    \"\"\"Get name of reanalysis surface u-wind field.\"\"\"\n",
    "    \n",
    "    if reanalysis == 'jra55':\n",
    "        return 'UGRD_GDS0_HTGL'\n",
    "\n",
    "    if reanalysis == 'nnr1':\n",
    "        return 'uwnd'\n",
    "    \n",
    "    raise ValueError(\"Unrecognized reanalysis '%r'\" % reanalysis)\n",
    "    \n",
    "    \n",
    "def get_reanalysis_vsfc_variable(reanalysis):\n",
    "    \"\"\"Get name of reanalysis surface v-wind field.\"\"\"\n",
    "    \n",
    "    if reanalysis == 'jra55':\n",
    "        return 'VGRD_GDS0_HTGL'\n",
    "\n",
    "    if reanalysis == 'nnr1':\n",
    "        return 'vwnd'\n",
    "    \n",
    "    raise ValueError(\"Unrecognized reanalysis '%r'\" % reanalysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_coordinate_names(ds, input_lat_name=None, output_lat_name='lat',\n",
    "                               input_lon_name=None, output_lon_name='lon',\n",
    "                               input_time_name=None, output_time_name='time'):\n",
    "    \"\"\"Rename coordinates.\"\"\"\n",
    "    \n",
    "    input_lat_name = input_lat_name if input_lat_name is not None else rdu.get_lat_name(ds)\n",
    "    input_lon_name = input_lon_name if input_lon_name is not None else rdu.get_lon_name(ds)\n",
    "    input_time_name = input_time_name if input_time_name is not None else rdu.get_time_name(ds)\n",
    "    \n",
    "    output_lat_name = output_lat_name if output_lat_name is not None else rdu.get_lat_name(ds)\n",
    "    output_lon_name = output_lon_name if output_lon_name is not None else rdu.get_lon_name(ds)\n",
    "    output_time_name = output_time_name if output_time_name is not None else rdu.get_time_name(ds)\n",
    "    \n",
    "    coords_to_rename = {}\n",
    "\n",
    "    if input_lat_name != output_lat_name:\n",
    "        coords_to_rename[input_lat_name] = output_lat_name\n",
    "        \n",
    "    if input_lon_name != output_lon_name:\n",
    "        coords_to_rename[input_lon_name] = output_lon_name\n",
    "\n",
    "    if input_time_name != output_time_name:\n",
    "        coords_to_rename[input_time_name] = output_time_name\n",
    "        \n",
    "    if coords_to_rename:\n",
    "        return ds.rename(coords_to_rename)\n",
    "    \n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mei_input_files = {\n",
    "    'jra55': {\n",
    "        'sst': os.path.join(get_reanalysis_fields_dir('jra55'), 'fcst_surf125.118_brtmp.1958010100_2018123100.daily.2.5x2.5.nc'),\n",
    "        'olr': os.path.join(get_reanalysis_fields_dir('jra55'), 'jra.55.ulwrf.ntat.1958010100_2018123121.daily.2.5x2.5.nc'),\n",
    "        'uwnd': os.path.join(get_reanalysis_fields_dir('jra55'), 'anl_surf125.033_ugrd.1958010100_2018123100.daily.2.5x2.5.nc'),\n",
    "        'vwnd': os.path.join(get_reanalysis_fields_dir('jra55'), 'anl_surf125.034_vgrd.1958010100_2018123100.daily.2.5x2.5.nc'),\n",
    "        'slp': os.path.join(get_reanalysis_fields_dir('jra55'), 'anl_surf125.002_prmsl.1958010100_2018123100.daily.2.5x2.5.nc'),\n",
    "    },\n",
    "    'nnr1': {\n",
    "        'sst': os.path.join(get_reanalysis_fields_dir('hadisst'), 'HadISST_sst.2.5x2.5.nc'),\n",
    "        'olr': os.path.join(get_reanalysis_fields_dir('nnr1'), 'nnr1.ulwrf.ntat.gauss.19480101_20200530.2.5x2.5.nc'),\n",
    "        'uwnd': os.path.join(get_reanalysis_fields_dir('nnr1'), 'nnr1.uwnd.sig995.19480101_20200530.2.5x2.5.nc'),\n",
    "        'vwnd': os.path.join(get_reanalysis_fields_dir('nnr1'), 'nnr1.vwnd.sig995.19480101_20200530.2.5x2.5.nc'),\n",
    "        'slp': os.path.join(get_reanalysis_fields_dir('nnr1'), 'nnr1.slp.19480101_20200530.2.5x2.5.nc'),\n",
    "    }\n",
    "}\n",
    "\n",
    "for reanalysis in mei_input_files:\n",
    "    \n",
    "    print('* Reanalysis: ', reanalysis)\n",
    "\n",
    "            \n",
    "    print('\\t- Preparing data ...', end='')\n",
    "\n",
    "    if reanalysis not in output_files:\n",
    "        output_files[reanalysis] = {}\n",
    "\n",
    "    eofs_output_dir = get_reanalysis_eofs_nc_dir(reanalysis)\n",
    "    if not os.path.exists(eofs_output_dir):\n",
    "        os.makedirs(eofs_output_dir)\n",
    "        \n",
    "    indices_nc_output_dir = get_reanalysis_indices_nc_dir(reanalysis)\n",
    "    if not os.path.exists(indices_nc_output_dir):\n",
    "        os.makedirs(indices_nc_output_dir)\n",
    "        \n",
    "    indices_csv_output_dir = get_reanalysis_indices_csv_dir(reanalysis)\n",
    "    if not os.path.exists(indices_csv_output_dir):\n",
    "        os.makedirs(indices_csv_output_dir)\n",
    "\n",
    "    sst_var = get_reanalysis_sst_variable(reanalysis)\n",
    "    slp_var = get_reanalysis_slp_variable(reanalysis)\n",
    "    uwnd_var = get_reanalysis_usfc_variable(reanalysis)\n",
    "    vwnd_var = get_reanalysis_vsfc_variable(reanalysis)\n",
    "    olr_var = get_reanalysis_olr_variable(reanalysis)\n",
    "\n",
    "    input_datasets = {\n",
    "        'sst': xr.open_dataset(mei_input_files[reanalysis]['sst'])[sst_var],\n",
    "        'olr': xr.open_dataset(mei_input_files[reanalysis]['olr'])[olr_var],\n",
    "        'uwnd': xr.open_dataset(mei_input_files[reanalysis]['uwnd'])[uwnd_var],\n",
    "        'vwnd': xr.open_dataset(mei_input_files[reanalysis]['vwnd'])[vwnd_var],\n",
    "        'slp': xr.open_dataset(mei_input_files[reanalysis]['slp'])[slp_var]\n",
    "    }\n",
    "    \n",
    "    input_coords = {\n",
    "        'sst': {'input_lat_name': rdu.get_lat_name(input_datasets['sst']),\n",
    "                'input_lon_name': rdu.get_lon_name(input_datasets['sst']),\n",
    "                'input_time_name': rdu.get_time_name(input_datasets['sst'])},\n",
    "        'olr': {'input_lat_name': rdu.get_lat_name(input_datasets['olr']),\n",
    "                'input_lon_name': rdu.get_lon_name(input_datasets['olr']),\n",
    "                'input_time_name': rdu.get_time_name(input_datasets['olr'])},\n",
    "        'uwnd': {'input_lat_name': rdu.get_lat_name(input_datasets['uwnd']),\n",
    "                 'input_lon_name': rdu.get_lon_name(input_datasets['uwnd']),\n",
    "                 'input_time_name': rdu.get_time_name(input_datasets['uwnd'])},\n",
    "        'vwnd': {'input_lat_name': rdu.get_lat_name(input_datasets['vwnd']),\n",
    "                 'input_lon_name': rdu.get_lon_name(input_datasets['vwnd']),\n",
    "                 'input_time_name': rdu.get_time_name(input_datasets['vwnd'])},\n",
    "        'slp': {'input_lat_name': rdu.get_lat_name(input_datasets['slp']),\n",
    "                'input_lon_name': rdu.get_lon_name(input_datasets['slp']),\n",
    "                'input_time_name': rdu.get_time_name(input_datasets['slp'])}\n",
    "    }\n",
    "    \n",
    "    for field in input_datasets:\n",
    "        \n",
    "        input_datasets[field] = normalize_coordinate_names(\n",
    "            input_datasets[field], **input_coords[field])\n",
    "        \n",
    "        # Ensure common time-period.\n",
    "        input_datasets[field] = input_datasets[field].where(\n",
    "            input_datasets[field]['time'].dt.year >= START_YEAR,\n",
    "            drop=True)\n",
    "        \n",
    "        # Ensure monthly input.\n",
    "        input_datasets[field] = input_datasets[field].resample(time='1MS').mean('time')\n",
    "        \n",
    "        # Where intermittent missing values are present for a given grid point,\n",
    "        # fill all times at that point with missing values.\n",
    "        input_datasets[field] = propagate_missing_values_through_time(\n",
    "            input_datasets[field], time_name='time')\n",
    "\n",
    "    end_time = time.perf_counter()\n",
    "    print(' (time: {:.2f}s)'.format(end_time - start_time))\n",
    "\n",
    "    print('\\t- MEI ...', end='')\n",
    "    start_time = time.perf_counter()\n",
    "\n",
    "    daily_mei_ds = rdi.mei(\n",
    "        input_datasets['slp'],\n",
    "        input_datasets['uwnd'],\n",
    "        input_datasets['vwnd'],\n",
    "        input_datasets['sst'],\n",
    "        input_datasets['olr'],\n",
    "        frequency='daily', base_period=BASE_PERIOD)\n",
    "        \n",
    "    monthly_mei_ds = rdi.mei(\n",
    "        input_datasets['slp'],\n",
    "        input_datasets['uwnd'],\n",
    "        input_datasets['vwnd'],\n",
    "        input_datasets['sst'],\n",
    "        input_datasets['olr'],\n",
    "        frequency='monthly', base_period=BASE_PERIOD)\n",
    "        \n",
    "    # Write EOFs to file.\n",
    "    base_period_str = get_timespan_string(BASE_PERIOD)\n",
    "\n",
    "    eofs_output_dir = get_reanalysis_eofs_nc_dir(reanalysis)\n",
    "\n",
    "    eofs_output_file = '.'.join(\n",
    "        [reanalysis, base_period_str, 'mei', 'monthly', 'eofs', 'nc'])\n",
    "    eofs_output_file = os.path.join(eofs_output_dir, eofs_output_file)\n",
    "    \n",
    "    loadings_ds = xr.Dataset(\n",
    "        {'mslp_pattern': monthly_mei_ds['mslp_pattern'],\n",
    "         'uwnd_pattern': monthly_mei_ds['uwnd_pattern'],\n",
    "         'vwnd_pattern': monthly_mei_ds['vwnd_pattern'],\n",
    "         'sst_pattern': monthly_mei_ds['sst_pattern'],\n",
    "         'olr_pattern': monthly_mei_ds['olr_pattern']})\n",
    "\n",
    "    for attr in monthly_mei_ds.attrs:\n",
    "        loadings_ds.attrs[attr] = monthly_mei_ds.attrs[attr]\n",
    "    for field in input_datasets:\n",
    "        loadings_ds.attrs['{}_input_file'.format(field)] = mei_input_files[reanalysis][field]\n",
    "\n",
    "    loadings_ds.to_netcdf(eofs_output_file)\n",
    "\n",
    "    # Write daily index to file.\n",
    "    daily_index_ds = daily_mei_ds['index'].to_dataset(name='mei')\n",
    "    for attr in daily_mei_ds.attrs:\n",
    "        daily_index_ds.attrs[attr] = daily_mei_ds.attrs[attr]\n",
    "    for field in input_datasets:\n",
    "        daily_index_ds.attrs['{}_input_file'.format(field)] = mei_input_files[reanalysis][field]\n",
    "\n",
    "    daily_index_nc_output_file = write_index_nc_file(\n",
    "        reanalysis, 'mei', daily_index_ds, base_period=BASE_PERIOD,\n",
    "        frequency='daily', output_dir=indices_nc_output_dir)\n",
    "    daily_index_csv_output_file = write_index_csv_file(\n",
    "        reanalysis, 'mei', daily_index_ds, 'mei',\n",
    "        base_period=BASE_PERIOD,\n",
    "        frequency='daily', output_dir=indices_csv_output_dir)\n",
    "    \n",
    "    # Write monthly index to file.\n",
    "    monthly_index_ds = monthly_mei_ds['index'].to_dataset(name='mei')\n",
    "    for attr in monthly_mei_ds.attrs:\n",
    "        monthly_index_ds.attrs[attr] = monthly_mei_ds.attrs[attr]\n",
    "    for field in input_datasets:\n",
    "        monthly_index_ds.attrs['{}_input_file'.format(field)] = mei_input_files[reanalysis][field]\n",
    "\n",
    "    monthly_index_nc_output_file = write_index_nc_file(\n",
    "        reanalysis, 'mei', monthly_index_ds, base_period=BASE_PERIOD,\n",
    "        frequency='monthly', output_dir=indices_nc_output_dir)\n",
    "    monthly_index_csv_output_file = write_index_csv_file(\n",
    "        reanalysis, 'mei', monthly_index_ds, 'mei',\n",
    "        base_period=BASE_PERIOD,\n",
    "        frequency='monthly', output_dir=indices_csv_output_dir)\n",
    "    \n",
    "    for field in input_datasets:\n",
    "        input_datasets[field].close()\n",
    "        \n",
    "    output_files[reanalysis]['MEI'] = {\n",
    "        'eofs_nc': eofs_output_file,\n",
    "        'daily_index_nc': daily_index_nc_output_file,\n",
    "        'daily_index_csv': daily_index_csv_output_file,\n",
    "        'monthly_index_nc': monthly_index_nc_output_file,\n",
    "        'monthly_index_csv': monthly_index_csv_output_file\n",
    "    }\n",
    "\n",
    "    end_time = time.perf_counter()\n",
    "    print(' (time: {:.2f}s)'.format(end_time - start_time))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MJO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reanalysis_uwnd_variable(reanalysis):\n",
    "    \"\"\"Get name of reanalysis u-wind field.\"\"\"\n",
    "    \n",
    "    if reanalysis == 'jra55':\n",
    "        return 'UGRD_GDS0_ISBL'\n",
    "    \n",
    "    if reanalysis == 'nnr1':\n",
    "        return 'uwnd'\n",
    "    \n",
    "    raise ValueError(\"Unrecognized reanalysis '%r'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mjo_input_files = {\n",
    "    'jra55': {\n",
    "        'olr': os.path.join(get_reanalysis_fields_dir('jra55'), 'jra.55.ulwrf.ntat.1958010100_2018123121.daily.2.5x2.5.nc'),\n",
    "        'u850': os.path.join(get_reanalysis_fields_dir('jra55'), 'jra.55.ugrd.850.1958010100_2016123118.2.5x2.5.nc'),\n",
    "        'u200': os.path.join(get_reanalysis_fields_dir('jra55'), 'jra.55.ugrd.250.1958010100_2016123118.2.5x2.5.nc'),\n",
    "        'enso_index': os.path.join(get_reanalysis_indices_nc_dir('jra55'), 'jra55.19790101_20011230.sst1_index.monthly.nc'),\n",
    "        'enso_index_name': 'sst1_index'\n",
    "    },\n",
    "    'nnr1': {\n",
    "        'olr': os.path.join(get_reanalysis_fields_dir('nnr1'), 'nnr1.ulwrf.ntat.gauss.19480101_20200530.2.5x2.5.nc'),\n",
    "        'u850': os.path.join(get_reanalysis_fields_dir('nnr1'), 'nnr1.uwnd.850.19480101_20200530.2.5x2.5.nc'),\n",
    "        'u200': os.path.join(get_reanalysis_fields_dir('nnr1'), 'nnr1.uwnd.200.19480101_20200530.2.5x2.5.nc'),\n",
    "        'enso_index': os.path.join(get_reanalysis_indices_nc_dir('hadisst'), 'hadisst.19790101_20011230.sst1_index.monthly.nc'),\n",
    "        'enso_index_name': 'sst1_index'\n",
    "    }\n",
    "}\n",
    "\n",
    "for reanalysis in mjo_input_files:\n",
    "    \n",
    "    print('* Reanalysis: ', reanalysis)\n",
    "\n",
    "            \n",
    "    print('\\t- Preparing data ...', end='')\n",
    "    start_time = time.perf_counter()\n",
    "\n",
    "    if reanalysis not in output_files:\n",
    "        output_files[reanalysis] = {}\n",
    "\n",
    "    eofs_output_dir = get_reanalysis_eofs_nc_dir(reanalysis)\n",
    "    if not os.path.exists(eofs_output_dir):\n",
    "        os.makedirs(eofs_output_dir)\n",
    "        \n",
    "    indices_nc_output_dir = get_reanalysis_indices_nc_dir(reanalysis)\n",
    "    if not os.path.exists(indices_nc_output_dir):\n",
    "        os.makedirs(indices_nc_output_dir)\n",
    "        \n",
    "    indices_csv_output_dir = get_reanalysis_indices_csv_dir(reanalysis)\n",
    "    if not os.path.exists(indices_csv_output_dir):\n",
    "        os.makedirs(indices_csv_output_dir)\n",
    "\n",
    "    uwnd_var = get_reanalysis_uwnd_variable(reanalysis)\n",
    "    olr_var = get_reanalysis_olr_variable(reanalysis)\n",
    "\n",
    "    input_datasets = {\n",
    "        'olr': xr.open_dataset(mjo_input_files[reanalysis]['olr'])[olr_var],\n",
    "        'u850': xr.open_dataset(mjo_input_files[reanalysis]['u850'])[uwnd_var],\n",
    "        'u200': xr.open_dataset(mjo_input_files[reanalysis]['u200'])[uwnd_var]\n",
    "    }\n",
    "    \n",
    "    input_coords = {\n",
    "        'olr': {'input_lat_name': rdu.get_lat_name(input_datasets['olr']),\n",
    "                'input_lon_name': rdu.get_lon_name(input_datasets['olr']),\n",
    "                'input_time_name': rdu.get_time_name(input_datasets['olr'])},\n",
    "        'u850': {'input_lat_name': rdu.get_lat_name(input_datasets['u850']),\n",
    "                 'input_lon_name': rdu.get_lon_name(input_datasets['u850']),\n",
    "                 'input_time_name': rdu.get_time_name(input_datasets['u850'])},\n",
    "        'u200': {'input_lat_name': rdu.get_lat_name(input_datasets['u200']),\n",
    "                 'input_lon_name': rdu.get_lon_name(input_datasets['u200']),\n",
    "                 'input_time_name': rdu.get_time_name(input_datasets['u200'])}\n",
    "    }\n",
    "    \n",
    "    for field in input_datasets:\n",
    "        \n",
    "        input_datasets[field] = normalize_coordinate_names(\n",
    "            input_datasets[field], **input_coords[field])\n",
    "        \n",
    "        # Ensure common time-period.\n",
    "        input_datasets[field] = input_datasets[field].where(\n",
    "            input_datasets[field]['time'].dt.year >= START_YEAR,\n",
    "            drop=True)\n",
    "        \n",
    "        # Ensure daily input.\n",
    "        input_datasets[field] = input_datasets[field].resample(time='1D').mean('time')\n",
    "        \n",
    "        # Where intermittent missing values are present for a given grid point,\n",
    "        # fill all times at that point with missing values.\n",
    "        input_datasets[field] = propagate_missing_values_through_time(\n",
    "            input_datasets[field], time_name='time')\n",
    "\n",
    "    enso_index = xr.open_dataset(\n",
    "            mjo_input_files[reanalysis]['enso_index'])[mjo_input_files[reanalysis]['enso_index_name']]\n",
    "    \n",
    "    enso_time_name = rdu.get_time_name(enso_index)\n",
    "    if enso_time_name != 'time':\n",
    "        enso_index = enso_index.rename({enso_time_name: 'time'})\n",
    "\n",
    "    end_time = time.perf_counter()\n",
    "    print(' (time: {:.2f}s)'.format(end_time - start_time))\n",
    "\n",
    "    print('\\t- RMM ...', end='')\n",
    "    start_time = time.perf_counter()\n",
    "\n",
    "    daily_rmm_ds = rdi.wh_rmm(\n",
    "        input_datasets['olr'],\n",
    "        input_datasets['u850'],\n",
    "        input_datasets['u200'],\n",
    "        enso_index=enso_index,\n",
    "        base_period=BASE_PERIOD)\n",
    "    \n",
    "    # Write EOFs to file.\n",
    "    base_period_str = get_timespan_string(BASE_PERIOD)\n",
    "\n",
    "    eofs_output_dir = get_reanalysis_eofs_nc_dir(reanalysis)\n",
    "\n",
    "    eofs_output_file = '.'.join(\n",
    "        [reanalysis, base_period_str, 'rmm', 'daily', 'eofs', 'nc'])\n",
    "    eofs_output_file = os.path.join(eofs_output_dir, eofs_output_file)\n",
    "    \n",
    "    loadings_ds = xr.Dataset(\n",
    "        {'olr_eofs': daily_rmm_ds['olr_eofs'],\n",
    "         'u850_eofs': daily_rmm_ds['u850_eofs'],\n",
    "         'u200_eofs': daily_rmm_ds['u200_eofs']})\n",
    "\n",
    "    for attr in daily_rmm_ds.attrs:\n",
    "        loadings_ds.attrs[attr] = daily_rmm_ds.attrs[attr]\n",
    "    for field in input_datasets:\n",
    "        loadings_ds.attrs['{}_input_file'.format(field)] = mjo_input_files[reanalysis][field]\n",
    "    loadings_ds.attrs['enso_input_file'] = mjo_input_files[reanalysis]['enso_index']\n",
    "\n",
    "    loadings_ds.to_netcdf(eofs_output_file)\n",
    "\n",
    "    output_files[reanalysis]['MJO'] = {'eofs_nc': eofs_output_file}\n",
    "\n",
    "    for index in ('rmm1', 'rmm2'):\n",
    "\n",
    "        # Write daily index to file.\n",
    "        daily_index_ds = daily_rmm_ds[index].to_dataset(name=index)\n",
    "        for attr in daily_rmm_ds.attrs:\n",
    "            daily_index_ds.attrs[attr] = daily_rmm_ds.attrs[attr]\n",
    "        for field in input_datasets:\n",
    "            daily_index_ds.attrs['{}_input_file'.format(field)] = mjo_input_files[reanalysis][field]\n",
    "        daily_index_ds.attrs['enso_input_file'] = mjo_input_files[reanalysis]['enso_index']\n",
    "\n",
    "        daily_index_nc_output_file = write_index_nc_file(\n",
    "            reanalysis, index, daily_index_ds, base_period=BASE_PERIOD,\n",
    "            frequency='daily', output_dir=indices_nc_output_dir)\n",
    "        daily_index_csv_output_file = write_index_csv_file(\n",
    "            reanalysis, index, daily_index_ds, index,\n",
    "            base_period=BASE_PERIOD,\n",
    "            frequency='daily', output_dir=indices_csv_output_dir)\n",
    "        \n",
    "        output_files[reanalysis]['MJO']['daily_{}_index_nc'.format(index)] = daily_index_nc_output_file\n",
    "        output_files[reanalysis]['MJO']['daily_{}_index_csv'.format(index)] = daily_index_csv_output_file\n",
    "\n",
    "    for field in input_datasets:\n",
    "        input_datasets[field].close()\n",
    "        \n",
    "    enso_index.close()\n",
    "\n",
    "    end_time = time.perf_counter()\n",
    "    print(' (time: {:.2f}s)'.format(end_time - start_time))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for reanalysis in output_files:\n",
    "    \n",
    "    if 'AO' not in output_files[reanalysis]:\n",
    "        continue\n",
    "\n",
    "    ds = xr.open_dataset(output_files[reanalysis]['AO']['eofs_nc'])\n",
    "    \n",
    "    lat_name = rdu.get_lat_name(ds)\n",
    "    lon_name = rdu.get_lon_name(ds)\n",
    "    \n",
    "    mode = int(ds.attrs['ao_mode'])\n",
    "    \n",
    "    vmin = np.min(ds['EOFs'].sel(mode=mode))\n",
    "    vmax = np.max(ds['EOFs'].sel(mode=mode))\n",
    "\n",
    "\n",
    "    if np.abs(vmax) > np.abs(vmin):\n",
    "        vmin = -np.abs(vmax)\n",
    "        vmax = np.abs(vmax)\n",
    "    else:\n",
    "        vmin = -np.abs(vmin)\n",
    "        vmax = np.abs(vmin)\n",
    "\n",
    "\n",
    "    fig = plt.figure(figsize=(4, 4))\n",
    "    gs = gridspec.GridSpec(nrows=2, ncols=1, height_ratios=[15, 1], hspace=0.05)\n",
    "\n",
    "    projection = ccrs.Orthographic(central_latitude=90)\n",
    "    cmap = plt.cm.RdBu_r\n",
    "\n",
    "    lat = ds[lat_name]\n",
    "    lon = ds[lon_name]\n",
    "\n",
    "    pattern = ds['EOFs'].sel(mode=mode).squeeze().data\n",
    "    explained_var = 100.0 * ds['explained_var'].sel(mode=mode).squeeze().values\n",
    "\n",
    "    pattern, lon = add_cyclic_point(pattern, coord=lon)\n",
    "    lon_grid, lat_grid = np.meshgrid(lon, lat)\n",
    "\n",
    "    ax = fig.add_subplot(gs[0, 0], projection=projection)\n",
    "\n",
    "    ax.coastlines()\n",
    "    ax.set_global()\n",
    "\n",
    "    cs = ax.pcolor(lon_grid, lat_grid, pattern, shading='auto',\n",
    "                   vmin=vmin, vmax=vmax, cmap=cmap, transform=ccrs.PlateCarree())\n",
    "\n",
    "    ax.set_title('{} mode {:d} ({:.2f}%)'.format(\n",
    "        get_reanalysis_full_name(reanalysis), mode + 1, explained_var), y=1.01, fontsize=14)\n",
    "    ax.set_aspect('equal')\n",
    "\n",
    "    cb_ax = fig.add_subplot(gs[-1, :])\n",
    "    cb = fig.colorbar(cs, cax=cb_ax, pad=0.05, orientation='horizontal')\n",
    "\n",
    "    ds.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {}\n",
    "for reanalysis in output_files:\n",
    "    \n",
    "    if 'AO' not in output_files[reanalysis]:\n",
    "        continue\n",
    "\n",
    "    datasets[reanalysis] = xr.open_dataset(output_files[reanalysis]['AO']['daily_index_nc'])\n",
    " \n",
    "    time_name = rdu.get_time_name(datasets[reanalysis])\n",
    "\n",
    "    if time_name != 'time':\n",
    "        datasets[reanalysis] = datasets[reanalysis].rename(\n",
    "            {time_name: 'time'})\n",
    "\n",
    "indices_to_plot = {get_reanalysis_full_name(reanalysis): datasets[reanalysis]['ao_index'] for reanalysis in datasets}\n",
    "\n",
    "ref_index_datafile = os.path.join(REF_INDICES_RESULTS_DIR, 'cpc.ao.daily.csv')\n",
    "\n",
    "if os.path.exists(ref_index_datafile):\n",
    "    ref_index_ds = read_reference_index_csv(ref_index_datafile)\n",
    "    indices_to_plot['CPC'] = ref_index_ds['index']\n",
    "\n",
    "fig = plot_indices_timeseries(indices_to_plot, years_per_row=10)\n",
    "\n",
    "plt.suptitle('Daily AO index (base period {} - {})'.format(\n",
    "        pd.to_datetime(BASE_PERIOD[0]).strftime('%Y%m%d'),\n",
    "        pd.to_datetime(BASE_PERIOD[1]).strftime('%Y%m%d')), fontsize=14, y=0.9)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "for reanalysis in datasets:\n",
    "    datasets[reanalysis].close()\n",
    "\n",
    "if os.path.exists(ref_index_datafile):\n",
    "    ref_index_ds.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {}\n",
    "for reanalysis in output_files:\n",
    "    \n",
    "    if 'AO' not in output_files[reanalysis]:\n",
    "        continue\n",
    "\n",
    "    datasets[reanalysis] = xr.open_dataset(output_files[reanalysis]['AO']['monthly_index_nc'])\n",
    " \n",
    "    time_name = rdu.get_time_name(datasets[reanalysis])\n",
    "\n",
    "    if time_name != 'time':\n",
    "        datasets[reanalysis] = datasets[reanalysis].rename(\n",
    "            {time_name: 'time'})\n",
    "\n",
    "indices_to_plot = {get_reanalysis_full_name(reanalysis): datasets[reanalysis]['ao_index'] for reanalysis in datasets}\n",
    "\n",
    "ref_index_datafile = os.path.join(REF_INDICES_RESULTS_DIR, 'cpc.ao.monthly.csv')\n",
    "\n",
    "if os.path.exists(ref_index_datafile):\n",
    "    ref_index_ds = read_reference_index_csv(ref_index_datafile)\n",
    "    indices_to_plot['CPC'] = ref_index_ds['index']\n",
    "\n",
    "fig = plot_indices_timeseries(indices_to_plot, years_per_row=10)\n",
    "\n",
    "plt.suptitle('Monthly AO index (base period {} - {})'.format(\n",
    "        pd.to_datetime(BASE_PERIOD[0]).strftime('%Y%m%d'),\n",
    "        pd.to_datetime(BASE_PERIOD[1]).strftime('%Y%m%d')), fontsize=14, y=0.9)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "for reanalysis in datasets:\n",
    "    datasets[reanalysis].close()\n",
    "\n",
    "if os.path.exists(ref_index_datafile):\n",
    "    ref_index_ds.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {}\n",
    "for reanalysis in output_files:\n",
    "    \n",
    "    if 'DMI' not in output_files[reanalysis]:\n",
    "        continue\n",
    "\n",
    "    datasets[reanalysis] = xr.open_dataset(output_files[reanalysis]['DMI']['weekly_index_nc'])\n",
    " \n",
    "    time_name = rdu.get_time_name(datasets[reanalysis])\n",
    "\n",
    "    if time_name != 'time':\n",
    "        datasets[reanalysis] = datasets[reanalysis].rename(\n",
    "            {time_name: 'time'})\n",
    "\n",
    "indices_to_plot = {get_reanalysis_full_name(reanalysis): datasets[reanalysis]['dmi'] for reanalysis in datasets}\n",
    "\n",
    "ref_index_datafile = os.path.join(REF_INDICES_RESULTS_DIR, 'bom.dmi.weekly.csv')\n",
    "\n",
    "if os.path.exists(ref_index_datafile):\n",
    "    ref_index_ds = read_reference_index_csv(ref_index_datafile)\n",
    "    indices_to_plot['BOM'] = ref_index_ds['index']\n",
    "\n",
    "fig = plot_indices_timeseries(indices_to_plot, years_per_row=10)\n",
    "\n",
    "plt.suptitle('Weekly DMI (base period {} - {})'.format(\n",
    "        pd.to_datetime(BASE_PERIOD[0]).strftime('%Y%m%d'),\n",
    "        pd.to_datetime(BASE_PERIOD[1]).strftime('%Y%m%d')), fontsize=14, y=0.9)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "for reanalysis in datasets:\n",
    "    datasets[reanalysis].close()\n",
    "\n",
    "if os.path.exists(ref_index_datafile):\n",
    "    ref_index_ds.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MEI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for reanalysis in output_files:\n",
    "    \n",
    "    if 'MEI' not in output_files[reanalysis]:\n",
    "        continue\n",
    "\n",
    "    ds = xr.open_dataset(output_files[reanalysis]['MEI']['eofs_nc'])\n",
    "    \n",
    "    lat_name = rdu.get_lat_name(ds)\n",
    "    lon_name = rdu.get_lon_name(ds)\n",
    "\n",
    "    patterns = {'MSLP': 'mslp_pattern', 'SST': 'sst_pattern', 'OLR': 'olr_pattern',\n",
    "                'u-wind': 'uwnd_pattern', 'v-wind': 'vwnd_pattern'}\n",
    "\n",
    "    for pattern in patterns:\n",
    "    \n",
    "        pattern_da = ds[patterns[pattern]]\n",
    "        seasons = pattern_da['season'].data\n",
    "        \n",
    "        vmin = np.min(pattern_da)\n",
    "        vmax = np.max(pattern_da)\n",
    "        \n",
    "        nrows = 4\n",
    "        ncols = 3\n",
    "        fig = plt.figure(figsize=(ncols * 5, nrows * 3))\n",
    "        height_ratios = nrows * [5] + [1,]\n",
    "\n",
    "        gs = gridspec.GridSpec(nrows=(nrows + 1), ncols=ncols, height_ratios=height_ratios,\n",
    "                               wspace=0.15, hspace=0.25)\n",
    "\n",
    "        projection = ccrs.PlateCarree(central_longitude=180)\n",
    "        cmap = plt.cm.RdBu_r\n",
    "\n",
    "        row_index = 0\n",
    "        col_index = 0\n",
    "        for season in seasons:\n",
    "\n",
    "            lat = pattern_da[lat_name]\n",
    "            lon = pattern_da[lon_name]\n",
    "            pattern_data = pattern_da.sel(season=season)\n",
    "\n",
    "            lon_grid, lat_grid = np.meshgrid(lon, lat)\n",
    "\n",
    "            ax = fig.add_subplot(gs[row_index, col_index], projection=projection)\n",
    "\n",
    "            ax.coastlines()\n",
    "            ax.set_extent([100, 290, -30, 30], ccrs.PlateCarree())\n",
    "            ax.set_aspect('auto')\n",
    "\n",
    "            ax.set_title('{}'.format(season), fontsize=12)\n",
    "\n",
    "            cs = ax.contourf(lon_grid, lat_grid, pattern_data, vmin=vmin, vmax=vmax,\n",
    "                             cmap=cmap, transform=ccrs.PlateCarree())\n",
    "            \n",
    "            col_index += 1\n",
    "            if col_index == ncols:\n",
    "                col_index = 0\n",
    "                row_index += 1\n",
    "\n",
    "        cb_ax = fig.add_subplot(gs[-1, :])\n",
    "        cb = fig.colorbar(cs, cax=cb_ax, pad=0.05, orientation='horizontal')\n",
    "\n",
    "        plt.suptitle('{} {} patterns (base period {} - {})'.format(\n",
    "                get_reanalysis_full_name(reanalysis), pattern,\n",
    "                pd.to_datetime(BASE_PERIOD[0]).strftime('%Y%m%d'),\n",
    "                pd.to_datetime(BASE_PERIOD[1]).strftime('%Y%m%d')),\n",
    "            fontsize=14, y=0.94)\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    ds.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {}\n",
    "for reanalysis in output_files:\n",
    "    \n",
    "    if 'MEI' not in output_files[reanalysis]:\n",
    "        continue\n",
    "\n",
    "    datasets[reanalysis] = xr.open_dataset(output_files[reanalysis]['MEI']['daily_index_nc'])\n",
    " \n",
    "    time_name = rdu.get_time_name(datasets[reanalysis])\n",
    "\n",
    "    if time_name != 'time':\n",
    "        datasets[reanalysis] = datasets[reanalysis].rename(\n",
    "            {time_name: 'time'})\n",
    "\n",
    "indices_to_plot = {get_reanalysis_full_name(reanalysis): datasets[reanalysis]['mei'] for reanalysis in datasets}\n",
    "\n",
    "fig = plot_indices_timeseries(indices_to_plot, years_per_row=10)\n",
    "\n",
    "plt.suptitle('Daily MEI (base period {} - {})'.format(\n",
    "        pd.to_datetime(BASE_PERIOD[0]).strftime('%Y%m%d'),\n",
    "        pd.to_datetime(BASE_PERIOD[1]).strftime('%Y%m%d')), fontsize=14, y=0.9)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "for reanalysis in datasets:\n",
    "    datasets[reanalysis].close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {}\n",
    "for reanalysis in output_files:\n",
    "    \n",
    "    if 'MEI' not in output_files[reanalysis]:\n",
    "        continue\n",
    "\n",
    "    datasets[reanalysis] = xr.open_dataset(output_files[reanalysis]['MEI']['monthly_index_nc'])\n",
    " \n",
    "    time_name = rdu.get_time_name(datasets[reanalysis])\n",
    "\n",
    "    if time_name != 'time':\n",
    "        datasets[reanalysis] = datasets[reanalysis].rename(\n",
    "            {time_name: 'time'})\n",
    "\n",
    "indices_to_plot = {get_reanalysis_full_name(reanalysis): datasets[reanalysis]['mei'] for reanalysis in datasets}\n",
    "\n",
    "ref_index_datafile = os.path.join(REF_INDICES_RESULTS_DIR, 'esrl.mei.bimonthly.csv')\n",
    "\n",
    "if os.path.exists(ref_index_datafile):\n",
    "    ref_index_ds = read_reference_index_csv(ref_index_datafile)\n",
    "    indices_to_plot['ESRL'] = ref_index_ds['index']\n",
    "\n",
    "fig = plot_indices_timeseries(indices_to_plot, years_per_row=10)\n",
    "\n",
    "plt.suptitle('Monthly MEI index (base period {} - {})'.format(\n",
    "        pd.to_datetime(BASE_PERIOD[0]).strftime('%Y%m%d'),\n",
    "        pd.to_datetime(BASE_PERIOD[1]).strftime('%Y%m%d')), fontsize=14, y=0.9)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "for reanalysis in datasets:\n",
    "    datasets[reanalysis].close()\n",
    "\n",
    "if os.path.exists(ref_index_datafile):\n",
    "    ref_index_ds.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MJO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for reanalysis in output_files:\n",
    "\n",
    "    if 'MJO' not in output_files[reanalysis]:\n",
    "        continue\n",
    "\n",
    "    ds = xr.open_dataset(output_files[reanalysis]['MJO']['eofs_nc'])\n",
    "    \n",
    "    lon_name = rdu.get_lon_name(ds)\n",
    "\n",
    "    fig = plt.figure(figsize=(6, 9))\n",
    "\n",
    "    gs = gridspec.GridSpec(nrows=2, ncols=1, wspace=0.25, hspace=0.3)\n",
    "\n",
    "    for mode in range(2):\n",
    "\n",
    "        ax = fig.add_subplot(gs[mode, 0])\n",
    "    \n",
    "        lons = ds[lon_name]\n",
    "    \n",
    "        ax.plot(lons, ds['olr_eofs'].sel(mode=mode), 'b-', label='OLR')\n",
    "        ax.plot(lons, ds['u850_eofs'].sel(mode=mode), 'r--', label='u850')\n",
    "        ax.plot(lons, ds['u200_eofs'].sel(mode=mode), 'g:', label='u200')\n",
    "\n",
    "        ax.grid(ls='--', color='gray', alpha=0.5)\n",
    "        ax.legend()\n",
    "\n",
    "        ax.tick_params(which='both', labelsize=12)\n",
    "        ax.set_xlabel('Longitude', fontsize=13)\n",
    "        ax.set_ylabel('Normalized magnitude', fontsize=13)\n",
    "        ax.set_title('EOF {:d}'.format(mode + 1), fontsize=13)\n",
    "\n",
    "    plt.suptitle('{} RMM EOFs (base period {} - {})'.format(\n",
    "            get_reanalysis_full_name(reanalysis),\n",
    "            pd.to_datetime(BASE_PERIOD[0]).strftime('%Y%m%d'),\n",
    "            pd.to_datetime(BASE_PERIOD[1]).strftime('%Y%m%d')),\n",
    "        fontsize=14, y=0.95)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    ds.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {}\n",
    "for reanalysis in output_files:\n",
    "    \n",
    "    if 'MJO' not in output_files[reanalysis]:\n",
    "        continue\n",
    "\n",
    "    datasets[reanalysis] = xr.open_dataset(output_files[reanalysis]['MJO']['daily_rmm1_index_nc'])\n",
    " \n",
    "    time_name = rdu.get_time_name(datasets[reanalysis])\n",
    "\n",
    "    if time_name != 'time':\n",
    "        datasets[reanalysis] = datasets[reanalysis].rename(\n",
    "            {time_name: 'time'})\n",
    "\n",
    "indices_to_plot = {get_reanalysis_full_name(reanalysis): datasets[reanalysis]['rmm1'] for reanalysis in datasets}\n",
    "\n",
    "ref_index_datafile = os.path.join(REF_INDICES_RESULTS_DIR, 'bom.rmm1.daily.csv')\n",
    "\n",
    "if os.path.exists(ref_index_datafile):\n",
    "    ref_index_ds = read_reference_index_csv(ref_index_datafile)\n",
    "    indices_to_plot['BOM'] = ref_index_ds['index']\n",
    "\n",
    "fig = plot_indices_timeseries(indices_to_plot, years_per_row=10)\n",
    "\n",
    "plt.suptitle('Daily RMM1 index (base period {} - {})'.format(\n",
    "        pd.to_datetime(BASE_PERIOD[0]).strftime('%Y%m%d'),\n",
    "        pd.to_datetime(BASE_PERIOD[1]).strftime('%Y%m%d')), fontsize=14, y=0.9)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "for reanalysis in datasets:\n",
    "    datasets[reanalysis].close()\n",
    "\n",
    "if os.path.exists(ref_index_datafile):\n",
    "    ref_index_ds.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {}\n",
    "for reanalysis in output_files:\n",
    "    \n",
    "    if 'MJO' not in output_files[reanalysis]:\n",
    "        continue\n",
    "\n",
    "    datasets[reanalysis] = xr.open_dataset(output_files[reanalysis]['MJO']['daily_rmm2_index_nc'])\n",
    " \n",
    "    time_name = rdu.get_time_name(datasets[reanalysis])\n",
    "\n",
    "    if time_name != 'time':\n",
    "        datasets[reanalysis] = datasets[reanalysis].rename(\n",
    "            {time_name: 'time'})\n",
    "\n",
    "indices_to_plot = {get_reanalysis_full_name(reanalysis): datasets[reanalysis]['rmm2'] for reanalysis in datasets}\n",
    "\n",
    "ref_index_datafile = os.path.join(REF_INDICES_RESULTS_DIR, 'bom.rmm2.daily.csv')\n",
    "\n",
    "if os.path.exists(ref_index_datafile):\n",
    "    ref_index_ds = read_reference_index_csv(ref_index_datafile)\n",
    "    indices_to_plot['BOM'] = ref_index_ds['index']\n",
    "\n",
    "fig = plot_indices_timeseries(indices_to_plot, years_per_row=10)\n",
    "\n",
    "plt.suptitle('Daily RMM2 index (base period {} - {})'.format(\n",
    "        pd.to_datetime(BASE_PERIOD[0]).strftime('%Y%m%d'),\n",
    "        pd.to_datetime(BASE_PERIOD[1]).strftime('%Y%m%d')), fontsize=14, y=0.9)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "for reanalysis in datasets:\n",
    "    datasets[reanalysis].close()\n",
    "\n",
    "if os.path.exists(ref_index_datafile):\n",
    "    ref_index_ds.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NHTELE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for reanalysis in output_files:\n",
    "    \n",
    "    if 'NHTELE' not in output_files[reanalysis]:\n",
    "        continue\n",
    "\n",
    "    ds = xr.open_dataset(output_files[reanalysis]['NHTELE']['composites_nc'])\n",
    "    \n",
    "    lat_name = rdu.get_lat_name(ds)\n",
    "    lon_name = rdu.get_lon_name(ds)\n",
    "\n",
    "    vmin = ds['composites'].min().item()\n",
    "    vmax = ds['composites'].max().item()\n",
    "            \n",
    "    if np.abs(vmax) > np.abs(vmin):\n",
    "        vmin = -np.abs(vmax)\n",
    "        vmax = np.abs(vmax)\n",
    "    else:\n",
    "        vmin = -np.abs(vmin)\n",
    "        vmax = np.abs(vmin)\n",
    "\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    gs = gridspec.GridSpec(nrows=3, ncols=2, height_ratios=[6, 6, 1], hspace=0.2)\n",
    "\n",
    "    projection = ccrs.Orthographic(central_latitude=90, central_longitude=0)\n",
    "    cmap = plt.cm.RdBu_r\n",
    "\n",
    "    row_index = 0\n",
    "    col_index = 0\n",
    "    for cluster in range(4):\n",
    "        \n",
    "        lat = ds[lat_name]\n",
    "        lon = ds[lon_name]\n",
    "\n",
    "        pattern = ds['composites'].sel(cluster=cluster).squeeze().data\n",
    "        \n",
    "        pattern, lon = add_cyclic_point(pattern, coord=lon)\n",
    "        \n",
    "        lon_grid, lat_grid = np.meshgrid(lon, lat)\n",
    "        \n",
    "        ax = fig.add_subplot(gs[row_index, col_index], projection=projection)\n",
    "        \n",
    "        ax.coastlines()\n",
    "        ax.set_global()\n",
    "\n",
    "        cs = ax.pcolor(lon_grid, lat_grid, pattern, shading='auto',\n",
    "                       vmin=vmin, vmax=vmax,\n",
    "                       cmap=cmap, transform=ccrs.PlateCarree())\n",
    "\n",
    "        ax.set_title('NHTELE{:d}'.format(cluster + 1))\n",
    "\n",
    "        ax.set_aspect('equal')\n",
    "        \n",
    "        col_index += 1\n",
    "        if col_index == 2:\n",
    "            col_index = 0\n",
    "            row_index += 1\n",
    "\n",
    "    cb_ax = fig.add_subplot(gs[-1, :])\n",
    "    cb = fig.colorbar(cs, cax=cb_ax, pad=0.05, orientation='horizontal')\n",
    "\n",
    "    plt.suptitle(\n",
    "        'Daily {} NH teleconnection patterns (base period {} - {})'.format(\n",
    "            get_reanalysis_full_name(reanalysis),\n",
    "            pd.to_datetime(BASE_PERIOD[0]).strftime('%Y%m%d'),\n",
    "            pd.to_datetime(BASE_PERIOD[1]).strftime('%Y%m%d')), y=0.95, fontsize=14)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    ds.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {}\n",
    "for reanalysis in output_files:\n",
    "    \n",
    "    if 'NHTELE' not in output_files[reanalysis]:\n",
    "        continue\n",
    "\n",
    "    datasets[reanalysis] = xr.open_dataset(output_files[reanalysis]['NHTELE']['daily_nhtele1_nc'])\n",
    " \n",
    "    time_name = rdu.get_time_name(datasets[reanalysis])\n",
    "\n",
    "    if time_name != 'time':\n",
    "        datasets[reanalysis] = datasets[reanalysis].rename(\n",
    "            {time_name: 'time'})\n",
    "\n",
    "indices_to_plot = {get_reanalysis_full_name(reanalysis): datasets[reanalysis]['nhtele1'] for reanalysis in datasets}\n",
    "\n",
    "fig = plot_indices_timeseries(indices_to_plot, years_per_row=10)\n",
    "\n",
    "plt.suptitle('Daily NHTELE1 index (base period {} - {})'.format(\n",
    "        pd.to_datetime(BASE_PERIOD[0]).strftime('%Y%m%d'),\n",
    "        pd.to_datetime(BASE_PERIOD[1]).strftime('%Y%m%d')), fontsize=14, y=0.9)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "for reanalysis in datasets:\n",
    "    datasets[reanalysis].close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {}\n",
    "for reanalysis in output_files:\n",
    "    \n",
    "    if 'NHTELE' not in output_files[reanalysis]:\n",
    "        continue\n",
    "\n",
    "    datasets[reanalysis] = xr.open_dataset(output_files[reanalysis]['NHTELE']['daily_nhtele2_nc'])\n",
    " \n",
    "    time_name = rdu.get_time_name(datasets[reanalysis])\n",
    "\n",
    "    if time_name != 'time':\n",
    "        datasets[reanalysis] = datasets[reanalysis].rename(\n",
    "            {time_name: 'time'})\n",
    "\n",
    "indices_to_plot = {get_reanalysis_full_name(reanalysis): datasets[reanalysis]['nhtele2'] for reanalysis in datasets}\n",
    "\n",
    "fig = plot_indices_timeseries(indices_to_plot, years_per_row=10)\n",
    "\n",
    "plt.suptitle('Daily NHTELE2 index (base period {} - {})'.format(\n",
    "        pd.to_datetime(BASE_PERIOD[0]).strftime('%Y%m%d'),\n",
    "        pd.to_datetime(BASE_PERIOD[1]).strftime('%Y%m%d')), fontsize=14, y=0.9)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "for reanalysis in datasets:\n",
    "    datasets[reanalysis].close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {}\n",
    "for reanalysis in output_files:\n",
    "    \n",
    "    if 'NHTELE' not in output_files[reanalysis]:\n",
    "        continue\n",
    "\n",
    "    datasets[reanalysis] = xr.open_dataset(output_files[reanalysis]['NHTELE']['daily_nhtele3_nc'])\n",
    " \n",
    "    time_name = rdu.get_time_name(datasets[reanalysis])\n",
    "\n",
    "    if time_name != 'time':\n",
    "        datasets[reanalysis] = datasets[reanalysis].rename(\n",
    "            {time_name: 'time'})\n",
    "\n",
    "indices_to_plot = {get_reanalysis_full_name(reanalysis): datasets[reanalysis]['nhtele3'] for reanalysis in datasets}\n",
    "\n",
    "fig = plot_indices_timeseries(indices_to_plot, years_per_row=10)\n",
    "\n",
    "plt.suptitle('Daily NHTELE3 index (base period {} - {})'.format(\n",
    "        pd.to_datetime(BASE_PERIOD[0]).strftime('%Y%m%d'),\n",
    "        pd.to_datetime(BASE_PERIOD[1]).strftime('%Y%m%d')), fontsize=14, y=0.9)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "for reanalysis in datasets:\n",
    "    datasets[reanalysis].close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {}\n",
    "for reanalysis in output_files:\n",
    "\n",
    "    if 'NHTELE' not in output_files[reanalysis]:\n",
    "        continue\n",
    "\n",
    "    datasets[reanalysis] = xr.open_dataset(output_files[reanalysis]['NHTELE']['daily_nhtele4_nc'])\n",
    " \n",
    "    time_name = rdu.get_time_name(datasets[reanalysis])\n",
    "\n",
    "    if time_name != 'time':\n",
    "        datasets[reanalysis] = datasets[reanalysis].rename(\n",
    "            {time_name: 'time'})\n",
    "\n",
    "indices_to_plot = {get_reanalysis_full_name(reanalysis): datasets[reanalysis]['nhtele4'] for reanalysis in datasets}\n",
    "\n",
    "fig = plot_indices_timeseries(indices_to_plot, years_per_row=10)\n",
    "\n",
    "plt.suptitle('Daily NHTELE4 index (base period {} - {})'.format(\n",
    "        pd.to_datetime(BASE_PERIOD[0]).strftime('%Y%m%d'),\n",
    "        pd.to_datetime(BASE_PERIOD[1]).strftime('%Y%m%d')), fontsize=14, y=0.9)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "for reanalysis in datasets:\n",
    "    datasets[reanalysis].close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {}\n",
    "for reanalysis in output_files:\n",
    "    \n",
    "    if 'NHTELE' not in output_files[reanalysis]:\n",
    "        continue\n",
    "\n",
    "    datasets[reanalysis] = xr.open_dataset(output_files[reanalysis]['NHTELE']['monthly_nhtele1_nc'])\n",
    " \n",
    "    time_name = rdu.get_time_name(datasets[reanalysis])\n",
    "\n",
    "    if time_name != 'time':\n",
    "        datasets[reanalysis] = datasets[reanalysis].rename(\n",
    "            {time_name: 'time'})\n",
    "\n",
    "indices_to_plot = {get_reanalysis_full_name(reanalysis): datasets[reanalysis]['nhtele1'] for reanalysis in datasets}\n",
    "\n",
    "fig = plot_indices_timeseries(indices_to_plot, years_per_row=10)\n",
    "\n",
    "plt.suptitle('Monthly NHTELE1 index (base period {} - {})'.format(\n",
    "        pd.to_datetime(BASE_PERIOD[0]).strftime('%Y%m%d'),\n",
    "        pd.to_datetime(BASE_PERIOD[1]).strftime('%Y%m%d')), fontsize=14, y=0.9)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "for reanalysis in datasets:\n",
    "    datasets[reanalysis].close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {}\n",
    "for reanalysis in output_files:\n",
    "    \n",
    "    if 'NHTELE' not in output_files[reanalysis]:\n",
    "        continue\n",
    "\n",
    "    datasets[reanalysis] = xr.open_dataset(output_files[reanalysis]['NHTELE']['monthly_nhtele2_nc'])\n",
    " \n",
    "    time_name = rdu.get_time_name(datasets[reanalysis])\n",
    "\n",
    "    if time_name != 'time':\n",
    "        datasets[reanalysis] = datasets[reanalysis].rename(\n",
    "            {time_name: 'time'})\n",
    "\n",
    "indices_to_plot = {get_reanalysis_full_name(reanalysis): datasets[reanalysis]['nhtele2'] for reanalysis in datasets}\n",
    "\n",
    "fig = plot_indices_timeseries(indices_to_plot, years_per_row=10)\n",
    "\n",
    "plt.suptitle('Monthly NHTELE2 index (base period {} - {})'.format(\n",
    "        pd.to_datetime(BASE_PERIOD[0]).strftime('%Y%m%d'),\n",
    "        pd.to_datetime(BASE_PERIOD[1]).strftime('%Y%m%d')), fontsize=14, y=0.9)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "for reanalysis in datasets:\n",
    "    datasets[reanalysis].close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {}\n",
    "for reanalysis in output_files:\n",
    "    \n",
    "    if 'NHTELE' not in output_files[reanalysis]:\n",
    "        continue\n",
    "\n",
    "    datasets[reanalysis] = xr.open_dataset(output_files[reanalysis]['NHTELE']['monthly_nhtele3_nc'])\n",
    " \n",
    "    time_name = rdu.get_time_name(datasets[reanalysis])\n",
    "\n",
    "    if time_name != 'time':\n",
    "        datasets[reanalysis] = datasets[reanalysis].rename(\n",
    "            {time_name: 'time'})\n",
    "\n",
    "indices_to_plot = {get_reanalysis_full_name(reanalysis): datasets[reanalysis]['nhtele3'] for reanalysis in datasets}\n",
    "\n",
    "fig = plot_indices_timeseries(indices_to_plot, years_per_row=10)\n",
    "\n",
    "plt.suptitle('Monthly NHTELE3 index (base period {} - {})'.format(\n",
    "        pd.to_datetime(BASE_PERIOD[0]).strftime('%Y%m%d'),\n",
    "        pd.to_datetime(BASE_PERIOD[1]).strftime('%Y%m%d')), fontsize=14, y=0.9)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "for reanalysis in datasets:\n",
    "    datasets[reanalysis].close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {}\n",
    "for reanalysis in output_files:\n",
    "    \n",
    "    if 'NHTELE' not in output_files[reanalysis]:\n",
    "        continue\n",
    "\n",
    "    datasets[reanalysis] = xr.open_dataset(output_files[reanalysis]['NHTELE']['monthly_nhtele4_nc'])\n",
    " \n",
    "    time_name = rdu.get_time_name(datasets[reanalysis])\n",
    "\n",
    "    if time_name != 'time':\n",
    "        datasets[reanalysis] = datasets[reanalysis].rename(\n",
    "            {time_name: 'time'})\n",
    "\n",
    "indices_to_plot = {get_reanalysis_full_name(reanalysis): datasets[reanalysis]['nhtele4'] for reanalysis in datasets}\n",
    "\n",
    "fig = plot_indices_timeseries(indices_to_plot, years_per_row=10)\n",
    "\n",
    "plt.suptitle('Monthly NHTELE4 index (base period {} - {})'.format(\n",
    "        pd.to_datetime(BASE_PERIOD[0]).strftime('%Y%m%d'),\n",
    "        pd.to_datetime(BASE_PERIOD[1]).strftime('%Y%m%d')), fontsize=14, y=0.9)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "for reanalysis in datasets:\n",
    "    datasets[reanalysis].close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for reanalysis in output_files:\n",
    "    \n",
    "    if 'PNA' not in output_files[reanalysis]:\n",
    "        continue\n",
    "\n",
    "    ds = xr.open_dataset(output_files[reanalysis]['PNA']['eofs_nc'])\n",
    "    \n",
    "    lat_name = rdu.get_lat_name(ds)\n",
    "    lon_name = rdu.get_lon_name(ds)\n",
    "    \n",
    "    mode = int(ds.attrs['pna_mode'])\n",
    "    \n",
    "    vmin = np.min(ds['EOFs'].sel(mode=mode))\n",
    "    vmax = np.max(ds['EOFs'].sel(mode=mode))\n",
    "\n",
    "\n",
    "    if np.abs(vmax) > np.abs(vmin):\n",
    "        vmin = -np.abs(vmax)\n",
    "        vmax = np.abs(vmax)\n",
    "    else:\n",
    "        vmin = -np.abs(vmin)\n",
    "        vmax = np.abs(vmin)\n",
    "\n",
    "\n",
    "    fig = plt.figure(figsize=(4, 4))\n",
    "    gs = gridspec.GridSpec(nrows=2, ncols=1, height_ratios=[15, 1], hspace=0.05)\n",
    "\n",
    "    projection = ccrs.Orthographic(central_latitude=90, central_longitude=280)\n",
    "    cmap = plt.cm.RdBu_r\n",
    "\n",
    "    lat = ds[lat_name]\n",
    "    lon = ds[lon_name]\n",
    "\n",
    "    pattern = ds['EOFs'].sel(mode=mode).squeeze().data\n",
    "    explained_var = 100.0 * ds['explained_var'].sel(mode=mode).squeeze().values\n",
    "\n",
    "    pattern, lon = add_cyclic_point(pattern, coord=lon)\n",
    "    lon_grid, lat_grid = np.meshgrid(lon, lat)\n",
    "\n",
    "    ax = fig.add_subplot(gs[0, 0], projection=projection)\n",
    "\n",
    "    ax.coastlines()\n",
    "    ax.set_global()\n",
    "\n",
    "    cs = ax.pcolor(lon_grid, lat_grid, pattern, shading='auto',\n",
    "                   vmin=vmin, vmax=vmax, cmap=cmap, transform=ccrs.PlateCarree())\n",
    "\n",
    "    ax.set_title('{} mode {:d} ({:.2f}%)'.format(\n",
    "        get_reanalysis_full_name(reanalysis), mode + 1, explained_var), y=1.01, fontsize=14)\n",
    "    ax.set_aspect('equal')\n",
    "\n",
    "    cb_ax = fig.add_subplot(gs[-1, :])\n",
    "    cb = fig.colorbar(cs, cax=cb_ax, pad=0.05, orientation='horizontal')\n",
    "\n",
    "    ds.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {}\n",
    "for reanalysis in output_files:\n",
    "    \n",
    "    if 'PNA' not in output_files[reanalysis]:\n",
    "        continue\n",
    "\n",
    "    datasets[reanalysis] = xr.open_dataset(output_files[reanalysis]['PNA']['daily_index_nc'])\n",
    " \n",
    "    time_name = rdu.get_time_name(datasets[reanalysis])\n",
    "\n",
    "    if time_name != 'time':\n",
    "        datasets[reanalysis] = datasets[reanalysis].rename(\n",
    "            {time_name: 'time'})\n",
    "\n",
    "indices_to_plot = {get_reanalysis_full_name(reanalysis): datasets[reanalysis]['pna_index'] for reanalysis in datasets}\n",
    "\n",
    "ref_index_datafile = os.path.join(REF_INDICES_RESULTS_DIR, 'cpc.pna.daily.csv')\n",
    "\n",
    "if os.path.exists(ref_index_datafile):\n",
    "    ref_index_ds = read_reference_index_csv(ref_index_datafile)\n",
    "    indices_to_plot['CPC'] = ref_index_ds['index']\n",
    "\n",
    "fig = plot_indices_timeseries(indices_to_plot, years_per_row=10)\n",
    "\n",
    "plt.suptitle('Daily PNA index (base period {} - {})'.format(\n",
    "        pd.to_datetime(BASE_PERIOD[0]).strftime('%Y%m%d'),\n",
    "        pd.to_datetime(BASE_PERIOD[1]).strftime('%Y%m%d')), fontsize=14, y=0.9)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "for reanalysis in datasets:\n",
    "    datasets[reanalysis].close()\n",
    "\n",
    "if os.path.exists(ref_index_datafile):\n",
    "    ref_index_ds.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {}\n",
    "for reanalysis in output_files:\n",
    "    \n",
    "    if 'PNA' not in output_files[reanalysis]:\n",
    "        continue\n",
    "\n",
    "    datasets[reanalysis] = xr.open_dataset(output_files[reanalysis]['PNA']['monthly_index_nc'])\n",
    " \n",
    "    time_name = rdu.get_time_name(datasets[reanalysis])\n",
    "\n",
    "    if time_name != 'time':\n",
    "        datasets[reanalysis] = datasets[reanalysis].rename(\n",
    "            {time_name: 'time'})\n",
    "\n",
    "indices_to_plot = {get_reanalysis_full_name(reanalysis): datasets[reanalysis]['pna_index'] for reanalysis in datasets}\n",
    "\n",
    "ref_index_datafile = os.path.join(REF_INDICES_RESULTS_DIR, 'cpc.pna.monthly.csv')\n",
    "\n",
    "if os.path.exists(ref_index_datafile):\n",
    "    ref_index_ds = read_reference_index_csv(ref_index_datafile)\n",
    "    indices_to_plot['CPC'] = ref_index_ds['index']\n",
    "\n",
    "fig = plot_indices_timeseries(indices_to_plot, years_per_row=10)\n",
    "\n",
    "plt.suptitle('Monthly PNA index (base period {} - {})'.format(\n",
    "        pd.to_datetime(BASE_PERIOD[0]).strftime('%Y%m%d'),\n",
    "        pd.to_datetime(BASE_PERIOD[1]).strftime('%Y%m%d')), fontsize=14, y=0.9)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "for reanalysis in datasets:\n",
    "    datasets[reanalysis].close()\n",
    "\n",
    "if os.path.exists(ref_index_datafile):\n",
    "    ref_index_ds.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for reanalysis in output_files:\n",
    "    \n",
    "    if 'PSA' not in output_files[reanalysis]:\n",
    "        continue\n",
    "\n",
    "    ds = xr.open_dataset(output_files[reanalysis]['PSA']['eofs_nc'])\n",
    "    \n",
    "    psa1_mode = int(ds.attrs['psa1_mode'])\n",
    "    psa2_mode = int(ds.attrs['psa2_mode'])\n",
    "    \n",
    "    lat_name = rdu.get_lat_name(ds)\n",
    "    lon_name = rdu.get_lon_name(ds)\n",
    "\n",
    "    vmin = min(np.min(ds['EOFs'].sel(mode=psa1_mode)),\n",
    "               np.min(ds['EOFs'].sel(mode=psa2_mode)))\n",
    "    vmax = max(np.max(ds['EOFs'].sel(mode=psa1_mode)),\n",
    "               np.max(ds['EOFs'].sel(mode=psa2_mode)))\n",
    "    \n",
    "    if np.abs(vmax) > np.abs(vmin):\n",
    "        vmin = -np.abs(vmax)\n",
    "        vmax = np.abs(vmax)\n",
    "    else:\n",
    "        vmin = -np.abs(vmin)\n",
    "        vmax = np.abs(vmin)\n",
    "\n",
    "    fig = plt.figure(figsize=(6, 8))\n",
    "    gs = gridspec.GridSpec(nrows=3, ncols=1, height_ratios=[6, 6, 1], hspace=0.2)\n",
    "\n",
    "    projection = ccrs.PlateCarree(central_longitude=180)\n",
    "    cmap = plt.cm.RdBu_r\n",
    "    \n",
    "    lat = ds[lat_name]\n",
    "    lon = ds[lon_name]\n",
    "    \n",
    "    psa1_pattern = ds['EOFs'].sel(mode=psa1_mode).squeeze().data\n",
    "    psa2_pattern = ds['EOFs'].sel(mode=psa2_mode).squeeze().data\n",
    "    \n",
    "    psa1_explained_var = 100.0 * ds['explained_var'].sel(mode=psa1_mode).squeeze().values\n",
    "    psa2_explained_var = 100.0 * ds['explained_var'].sel(mode=psa2_mode).squeeze().values\n",
    "\n",
    "    psa1_pattern, _ = add_cyclic_point(psa1_pattern, coord=lon)\n",
    "    psa2_pattern, lon = add_cyclic_point(psa2_pattern, coord=lon)\n",
    "\n",
    "    lon_grid, lat_grid = np.meshgrid(lon, lat)\n",
    "\n",
    "    ax = fig.add_subplot(gs[0, 0], projection=projection)\n",
    "\n",
    "    ax.coastlines()\n",
    "\n",
    "    ax.set_extent([0, 357.5, -90, -20], ccrs.PlateCarree(central_longitude=180))\n",
    "    ax.set_aspect('auto')\n",
    "\n",
    "    cs = ax.pcolor(lon_grid, lat_grid, psa1_pattern, shading='auto',\n",
    "                   vmin=vmin, vmax=vmax,\n",
    "                   cmap=cmap, transform=ccrs.PlateCarree())\n",
    "\n",
    "    ax.set_title(\n",
    "        'Mode {:d} ({:.2f}%)'.format(\n",
    "            psa1_mode + 1, psa1_explained_var\n",
    "            ), y=1.01, fontsize=14)\n",
    "\n",
    "    ax = fig.add_subplot(gs[1, 0], projection=projection)\n",
    "\n",
    "    ax.coastlines()\n",
    "\n",
    "    cs = ax.pcolor(lon_grid, lat_grid, psa2_pattern, shading='auto',\n",
    "                   vmin=vmin, vmax=vmax,\n",
    "                   cmap=cmap, transform=ccrs.PlateCarree())\n",
    "\n",
    "    ax.set_extent([0, 357.5, -90, -20], ccrs.PlateCarree(central_longitude=180))\n",
    "    ax.set_aspect('auto')\n",
    "\n",
    "    ax.set_title(\n",
    "        'Mode {:d} ({:.2f}%)'.format(\n",
    "            psa2_mode + 1, psa2_explained_var\n",
    "            ), y=1.01, fontsize=14)\n",
    "\n",
    "    cb_ax = fig.add_subplot(gs[-1, :])\n",
    "    cb = fig.colorbar(cs, cax=cb_ax, pad=0.05, orientation='horizontal')\n",
    "\n",
    "    plt.suptitle('{} daily PSA patterns (base period {} - {})'.format(\n",
    "        get_reanalysis_full_name(reanalysis),\n",
    "        pd.to_datetime(BASE_PERIOD[0]).strftime('%Y%m%d'),\n",
    "        pd.to_datetime(BASE_PERIOD[1]).strftime('%Y%m%d')),\n",
    "                fontsize=14, y=0.98)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    ds.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {}\n",
    "for reanalysis in output_files:\n",
    "    \n",
    "    if 'PSA' not in output_files[reanalysis]:\n",
    "        continue\n",
    "\n",
    "    datasets[reanalysis] = xr.open_dataset(output_files[reanalysis]['PSA']['daily_psa1_index_nc'])\n",
    " \n",
    "    time_name = rdu.get_time_name(datasets[reanalysis])\n",
    "\n",
    "    if time_name != 'time':\n",
    "        datasets[reanalysis] = datasets[reanalysis].rename(\n",
    "            {time_name: 'time'})\n",
    "\n",
    "indices_to_plot = {get_reanalysis_full_name(reanalysis): datasets[reanalysis]['psa1_index'] for reanalysis in datasets}\n",
    "\n",
    "fig = plot_indices_timeseries(indices_to_plot, years_per_row=10)\n",
    "\n",
    "plt.suptitle('Daily PSA1 index (base period {} - {})'.format(\n",
    "        pd.to_datetime(BASE_PERIOD[0]).strftime('%Y%m%d'),\n",
    "        pd.to_datetime(BASE_PERIOD[1]).strftime('%Y%m%d')), fontsize=14, y=0.9)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "for reanalysis in datasets:\n",
    "    datasets[reanalysis].close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {}\n",
    "for reanalysis in output_files:\n",
    "    \n",
    "    if 'PSA' not in output_files[reanalysis]:\n",
    "        continue\n",
    "\n",
    "    datasets[reanalysis] = xr.open_dataset(output_files[reanalysis]['PSA']['daily_psa2_index_nc'])\n",
    " \n",
    "    time_name = rdu.get_time_name(datasets[reanalysis])\n",
    "\n",
    "    if time_name != 'time':\n",
    "        datasets[reanalysis] = datasets[reanalysis].rename(\n",
    "            {time_name: 'time'})\n",
    "\n",
    "indices_to_plot = {get_reanalysis_full_name(reanalysis): datasets[reanalysis]['psa2_index'] for reanalysis in datasets}\n",
    "\n",
    "fig = plot_indices_timeseries(indices_to_plot, years_per_row=10)\n",
    "\n",
    "plt.suptitle('Daily PSA2 index (base period {} - {})'.format(\n",
    "        pd.to_datetime(BASE_PERIOD[0]).strftime('%Y%m%d'),\n",
    "        pd.to_datetime(BASE_PERIOD[1]).strftime('%Y%m%d')), fontsize=14, y=0.9)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "for reanalysis in datasets:\n",
    "    datasets[reanalysis].close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {}\n",
    "for reanalysis in output_files:\n",
    "    \n",
    "    if 'PSA' not in output_files[reanalysis]:\n",
    "        continue\n",
    "\n",
    "    datasets[reanalysis] = xr.open_dataset(output_files[reanalysis]['PSA']['monthly_psa1_index_nc'])\n",
    " \n",
    "    time_name = rdu.get_time_name(datasets[reanalysis])\n",
    "\n",
    "    if time_name != 'time':\n",
    "        datasets[reanalysis] = datasets[reanalysis].rename(\n",
    "            {time_name: 'time'})\n",
    "\n",
    "indices_to_plot = {get_reanalysis_full_name(reanalysis): datasets[reanalysis]['psa1_index'] for reanalysis in datasets}\n",
    "\n",
    "fig = plot_indices_timeseries(indices_to_plot, years_per_row=10)\n",
    "\n",
    "plt.suptitle('Monthly PSA1 index (base period {} - {})'.format(\n",
    "        pd.to_datetime(BASE_PERIOD[0]).strftime('%Y%m%d'),\n",
    "        pd.to_datetime(BASE_PERIOD[1]).strftime('%Y%m%d')), fontsize=14, y=0.9)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "for reanalysis in datasets:\n",
    "    datasets[reanalysis].close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {}\n",
    "for reanalysis in output_files:\n",
    "    \n",
    "    if 'PSA' not in output_files[reanalysis]:\n",
    "        continue\n",
    "\n",
    "    datasets[reanalysis] = xr.open_dataset(output_files[reanalysis]['PSA']['monthly_psa2_index_nc'])\n",
    " \n",
    "    time_name = rdu.get_time_name(datasets[reanalysis])\n",
    "\n",
    "    if time_name != 'time':\n",
    "        datasets[reanalysis] = datasets[reanalysis].rename(\n",
    "            {time_name: 'time'})\n",
    "\n",
    "indices_to_plot = {get_reanalysis_full_name(reanalysis): datasets[reanalysis]['psa2_index'] for reanalysis in datasets}\n",
    "\n",
    "fig = plot_indices_timeseries(indices_to_plot, years_per_row=10)\n",
    "\n",
    "plt.suptitle('Monthly PSA2 index (base period {} - {})'.format(\n",
    "        pd.to_datetime(BASE_PERIOD[0]).strftime('%Y%m%d'),\n",
    "        pd.to_datetime(BASE_PERIOD[1]).strftime('%Y%m%d')), fontsize=14, y=0.9)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "for reanalysis in datasets:\n",
    "    datasets[reanalysis].close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for reanalysis in output_files:\n",
    "    \n",
    "    if 'SAM' not in output_files[reanalysis]:\n",
    "        continue\n",
    "\n",
    "    ds = xr.open_dataset(output_files[reanalysis]['SAM']['eofs_nc'])\n",
    "    \n",
    "    lat_name = rdu.get_lat_name(ds)\n",
    "    lon_name = rdu.get_lon_name(ds)\n",
    "    \n",
    "    mode = int(ds.attrs['sam_mode'])\n",
    "    \n",
    "    vmin = np.min(ds['EOFs'].sel(mode=mode))\n",
    "    vmax = np.max(ds['EOFs'].sel(mode=mode))\n",
    "\n",
    "\n",
    "    if np.abs(vmax) > np.abs(vmin):\n",
    "        vmin = -np.abs(vmax)\n",
    "        vmax = np.abs(vmax)\n",
    "    else:\n",
    "        vmin = -np.abs(vmin)\n",
    "        vmax = np.abs(vmin)\n",
    "\n",
    "\n",
    "    fig = plt.figure(figsize=(4, 4))\n",
    "    gs = gridspec.GridSpec(nrows=2, ncols=1, height_ratios=[15, 1], hspace=0.05)\n",
    "\n",
    "    projection = ccrs.Orthographic(central_latitude=-90)\n",
    "    cmap = plt.cm.RdBu_r\n",
    "\n",
    "    lat = ds[lat_name]\n",
    "    lon = ds[lon_name]\n",
    "\n",
    "    pattern = ds['EOFs'].sel(mode=mode).squeeze().data\n",
    "    explained_var = 100.0 * ds['explained_var'].sel(mode=mode).squeeze().values\n",
    "\n",
    "    pattern, lon = add_cyclic_point(pattern, coord=lon)\n",
    "    lon_grid, lat_grid = np.meshgrid(lon, lat)\n",
    "\n",
    "    ax = fig.add_subplot(gs[0, 0], projection=projection)\n",
    "\n",
    "    ax.coastlines()\n",
    "    ax.set_global()\n",
    "\n",
    "    cs = ax.pcolor(lon_grid, lat_grid, pattern, shading='auto',\n",
    "                   vmin=vmin, vmax=vmax, cmap=cmap, transform=ccrs.PlateCarree())\n",
    "\n",
    "    ax.set_title('{} mode {:d} ({:.2f}%)'.format(\n",
    "        get_reanalysis_full_name(reanalysis), mode + 1, explained_var), y=1.01, fontsize=14)\n",
    "    ax.set_aspect('equal')\n",
    "\n",
    "    cb_ax = fig.add_subplot(gs[-1, :])\n",
    "    cb = fig.colorbar(cs, cax=cb_ax, pad=0.05, orientation='horizontal')\n",
    "\n",
    "    ds.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {}\n",
    "for reanalysis in output_files:\n",
    "    \n",
    "    if 'SAM' not in output_files[reanalysis]:\n",
    "        continue\n",
    "\n",
    "    datasets[reanalysis] = xr.open_dataset(output_files[reanalysis]['SAM']['daily_index_nc'])\n",
    " \n",
    "    time_name = rdu.get_time_name(datasets[reanalysis])\n",
    "\n",
    "    if time_name != 'time':\n",
    "        datasets[reanalysis] = datasets[reanalysis].rename(\n",
    "            {time_name: 'time'})\n",
    "\n",
    "indices_to_plot = {get_reanalysis_full_name(reanalysis): datasets[reanalysis]['sam_index'] for reanalysis in datasets}\n",
    "\n",
    "ref_index_datafile = os.path.join(REF_INDICES_RESULTS_DIR, 'cpc.sam.daily.csv')\n",
    "\n",
    "if os.path.exists(ref_index_datafile):\n",
    "    ref_index_ds = read_reference_index_csv(ref_index_datafile)\n",
    "    indices_to_plot['CPC'] = ref_index_ds['index']\n",
    "\n",
    "fig = plot_indices_timeseries(indices_to_plot, years_per_row=10)\n",
    "\n",
    "plt.suptitle('Daily SAM index (base period {} - {})'.format(\n",
    "        pd.to_datetime(BASE_PERIOD[0]).strftime('%Y%m%d'),\n",
    "        pd.to_datetime(BASE_PERIOD[1]).strftime('%Y%m%d')), fontsize=14, y=0.9)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "for reanalysis in datasets:\n",
    "    datasets[reanalysis].close()\n",
    "\n",
    "if os.path.exists(ref_index_datafile):\n",
    "    ref_index_ds.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {}\n",
    "for reanalysis in output_files:\n",
    "    \n",
    "    if 'SAM' not in output_files[reanalysis]:\n",
    "        continue\n",
    "\n",
    "    datasets[reanalysis] = xr.open_dataset(output_files[reanalysis]['SAM']['monthly_index_nc'])\n",
    " \n",
    "    time_name = rdu.get_time_name(datasets[reanalysis])\n",
    "\n",
    "    if time_name != 'time':\n",
    "        datasets[reanalysis] = datasets[reanalysis].rename(\n",
    "            {time_name: 'time'})\n",
    "\n",
    "indices_to_plot = {get_reanalysis_full_name(reanalysis): datasets[reanalysis]['sam_index'] for reanalysis in datasets}\n",
    "\n",
    "ref_index_datafile = os.path.join(REF_INDICES_RESULTS_DIR, 'cpc.sam.monthly.csv')\n",
    "\n",
    "if os.path.exists(ref_index_datafile):\n",
    "    ref_index_ds = read_reference_index_csv(ref_index_datafile)\n",
    "    indices_to_plot['CPC'] = ref_index_ds['index']\n",
    "\n",
    "fig = plot_indices_timeseries(indices_to_plot, years_per_row=10)\n",
    "\n",
    "plt.suptitle('Monthly SAM index (base period {} - {})'.format(\n",
    "        pd.to_datetime(BASE_PERIOD[0]).strftime('%Y%m%d'),\n",
    "        pd.to_datetime(BASE_PERIOD[1]).strftime('%Y%m%d')), fontsize=14, y=0.9)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "for reanalysis in datasets:\n",
    "    datasets[reanalysis].close()\n",
    "\n",
    "if os.path.exists(ref_index_datafile):\n",
    "    ref_index_ds.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
